{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The issue of pattern recognition (Electroencephalogram Signals)**\n",
    "\n",
    "##### **AI and Biological Computations project**\n",
    "\n",
    "##### **Tina Halimi**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import welch\n",
    "from scipy.integrate import simps\n",
    "from scipy.signal import periodogram\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('Project_data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 5000, 550)\n",
      "(1, 550)\n",
      "(59, 5000, 277)\n",
      "(59, 5000, 273)\n",
      "(59, 5000, 159)\n"
     ]
    }
   ],
   "source": [
    "# extracting data\n",
    "data_channels = data['Channels']\n",
    "data_fs = data['fs']\n",
    "training_data = data['TrainData']\n",
    "training_data_labels = data['TrainLabels']\n",
    "test_data = data['TestData']\n",
    "\n",
    "training_data_pos = training_data[:,:, training_data_labels[0,:] == 1]\n",
    "training_data_neg = training_data[:, :, training_data_labels[0,:] == -1]\n",
    "\n",
    "print(training_data.shape)\n",
    "print(training_data_labels.shape)\n",
    "print(training_data_pos.shape)\n",
    "print(training_data_neg.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher1D(mean_total,mean_positive,mean_negative,var_positive,var_negative):\n",
    "    sb = (mean_positive - mean_total)**2 + (mean_negative - mean_total) **2\n",
    "    sw = var_positive + var_negative\n",
    "    return sb/sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(input_array):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    transposed_array = np.transpose(input_array)\n",
    "    normalized_array_transposed = scaler.fit_transform(transposed_array)\n",
    "    normalized_array = np.transpose(normalized_array_transposed)\n",
    "\n",
    "    return normalized_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features of the frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishersOfFeatures_freq=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Maximum Frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def max_power_frequency(data, sampling_rate):\n",
    "\n",
    "    channels, samples, experiments = data.shape\n",
    "    max_power_freqs = np.zeros((channels,experiments))\n",
    "    \n",
    "    for channel in range(channels):\n",
    "        for experiment in range(experiments):\n",
    "\n",
    "            signal = data[channel, :, experiment]\n",
    "            frequencies, power_spectrum = periodogram(signal, sampling_rate)\n",
    "            frequencies = frequencies.ravel()\n",
    "            max_power_freq = np.argmax(power_spectrum)\n",
    "\n",
    "            max_power_freqs[channel, experiment] = frequencies[max_power_freq]\n",
    "\n",
    "    return np.array(max_power_freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 550)\n"
     ]
    }
   ],
   "source": [
    "#result\n",
    "max_freq = max_power_frequency(training_data,data_fs)\n",
    "print(max_freq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59,)\n",
      "fisher of Max Frequency feature: \n",
      "\n",
      "[1.11233581e-03 2.62065453e-05 2.66865597e-04 8.97682267e-04\n",
      " 4.22944460e-03 3.43219286e-04 3.02999010e-03 7.56429718e-03\n",
      " 2.08692441e-03 1.75142659e-04 1.82403612e-04 1.49703841e-03\n",
      " 5.26426672e-04 4.91131275e-03 1.00365235e-04 2.52625157e-03\n",
      " 3.03125545e-03 3.40073486e-03 3.79370916e-03 4.47843588e-04\n",
      " 1.02628641e-02 3.85509772e-03 2.25118113e-02 2.37471860e-02\n",
      " 1.62021549e-03 9.79055792e-05 1.57655824e-03 4.65118305e-06\n",
      " 1.88925159e-04 8.92823758e-03 4.89029084e-04 3.70838689e-03\n",
      " 3.78918506e-03 6.92575222e-03 5.92031027e-03 9.35608226e-04\n",
      " 3.56346412e-03 1.44063007e-03 3.86798230e-03 1.40852317e-02\n",
      " 4.35856010e-07 4.51917727e-07 2.35174138e-02 2.02593869e-04\n",
      " 4.65156222e-04 1.34994870e-06 3.26188476e-04 2.72353198e-03\n",
      " 1.22206326e-03 6.32949115e-03 1.67284617e-02 4.28974610e-04\n",
      " 1.65959464e-04 1.71965384e-02 1.29976269e-03 1.59202326e-03\n",
      " 1.07452552e-03 3.54510545e-03 6.64270426e-04]\n"
     ]
    }
   ],
   "source": [
    "# fisher calculation\n",
    "mean_total_max = np.mean(max_freq,axis=1)\n",
    "\n",
    "mean_pos_max = np.mean(max_freq[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "mean_neg_max = np.mean(max_freq[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "var_pos_max = np.var(max_freq[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "var_neg_max = np.var(max_freq[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "fisher_max_freq = fisher1D(mean_total_max, mean_pos_max, mean_neg_max, var_pos_max, var_neg_max)\n",
    "\n",
    "print(fisher_max_freq.shape)\n",
    "print('fisher of Max Frequency feature: \\n')\n",
    "print(fisher_max_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 159)\n"
     ]
    }
   ],
   "source": [
    "max_freq_test = max_power_frequency(test_data, data_fs)\n",
    "print(max_freq_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fisher_max_freq)):\n",
    "    fishersOfFeatures_freq.append([fisher_max_freq[i],'max_freq_channel' + str(i), max_freq[i],max_freq_test[i]])\n",
    "\n",
    "print(len(fishersOfFeatures_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Mean Frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def weighted_average_frequency(data, sampling_rate):\n",
    "    channels, samples, experiments = data.shape\n",
    "    weighted_avg_freqs = np.zeros((channels, experiments))\n",
    "    \n",
    "    for channel in range(channels):\n",
    "        for experiment in range(experiments):\n",
    "            signal = data[channel, :, experiment]\n",
    "            frequencies, power_spectrum = periodogram(signal, sampling_rate)\n",
    "            frequencies = frequencies.ravel()\n",
    "            \n",
    "            weighted_avg_freq = np.sum(abs(frequencies) * power_spectrum) / np.sum(power_spectrum)\n",
    "            weighted_avg_freqs[channel, experiment] = weighted_avg_freq\n",
    "\n",
    "    return np.array(weighted_avg_freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 550)\n"
     ]
    }
   ],
   "source": [
    "# result\n",
    "mean_freq = weighted_average_frequency(training_data,data_fs)\n",
    "print(mean_freq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59,)\n",
      "fisher of Mean Frequency feature: \n",
      "\n",
      "[3.53226012e-05 8.93360396e-04 9.32510044e-04 7.16705637e-06\n",
      " 1.30270756e-03 4.71071123e-03 2.23836044e-03 2.24672617e-04\n",
      " 1.53898343e-04 5.99652301e-05 2.54376013e-07 2.41280754e-04\n",
      " 3.89640234e-03 1.05173714e-03 2.87656093e-04 1.50652372e-03\n",
      " 5.17532004e-03 3.45501614e-04 4.18881783e-05 5.32379879e-03\n",
      " 2.88791770e-03 7.94393856e-03 2.45326741e-02 4.75426259e-03\n",
      " 1.55103874e-03 8.15722497e-03 3.49896211e-04 4.74848728e-05\n",
      " 1.38166870e-03 3.00275167e-03 1.08842566e-02 9.27766963e-03\n",
      " 1.88780801e-02 6.02426232e-03 3.57959154e-04 2.48179391e-03\n",
      " 6.21576126e-04 1.66573425e-03 6.00784184e-03 6.25403729e-03\n",
      " 2.38945444e-03 6.02398205e-03 1.09977381e-02 2.85530763e-03\n",
      " 1.30783818e-03 1.51143951e-03 8.22380003e-03 2.84242289e-03\n",
      " 8.74431885e-03 7.04702004e-03 7.77159156e-04 8.67835838e-04\n",
      " 8.66077511e-03 1.03330276e-02 3.81632883e-03 1.44130305e-02\n",
      " 6.80853457e-03 2.79089758e-05 1.79165018e-02]\n"
     ]
    }
   ],
   "source": [
    "# fisher\n",
    "mean_total_mean = np.mean(mean_freq,axis=1)\n",
    "\n",
    "mean_pos_mean = np.mean(mean_freq[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "mean_neg_mean = np.mean(mean_freq[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "var_pos_mean = np.var(mean_freq[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "var_neg_mean = np.var(mean_freq[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "fisher_mean_freq = fisher1D(mean_total_mean, mean_pos_mean, mean_neg_mean, var_pos_mean, var_neg_mean)\n",
    "\n",
    "print(fisher_mean_freq.shape)\n",
    "print('fisher of Mean Frequency feature: \\n')\n",
    "print(fisher_mean_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 159)\n"
     ]
    }
   ],
   "source": [
    "mean_freq_test = weighted_average_frequency(test_data,data_fs)\n",
    "print(mean_freq_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fisher_mean_freq)):\n",
    "    fishersOfFeatures_freq.append([fisher_mean_freq[i],'mean_freq_channel' + str(i), mean_freq[i], mean_freq_test[i]])\n",
    "\n",
    "print(len(fishersOfFeatures_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Median Frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def weighted_median_frequency(data, sampling_rate):\n",
    "\n",
    "    channels, samples, experiments = data.shape\n",
    "    weighted_median_freqs = np.zeros((channels, experiments))\n",
    "    \n",
    "    for channel in range(channels):\n",
    "        for experiment in range(experiments):\n",
    "\n",
    "            signal = data[channel, :, experiment]\n",
    "            frequencies, power_spectrum = periodogram(signal, sampling_rate)\n",
    "            frequencies = frequencies.ravel()\n",
    "            cumsum_power = np.cumsum(power_spectrum)\n",
    "\n",
    "            median_index = np.argmax(cumsum_power >= 0.5 * np.sum(power_spectrum))\n",
    "            \n",
    "            weighted_median_freq = frequencies[median_index]\n",
    "\n",
    "            weighted_median_freqs[channel, experiment] = weighted_median_freq\n",
    "\n",
    "    return np.array(weighted_median_freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 550)\n"
     ]
    }
   ],
   "source": [
    "# result\n",
    "mod_freq = weighted_median_frequency(training_data,data_fs)\n",
    "print(mod_freq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59,)\n",
      "fisher of Median Frequency feature: \n",
      "\n",
      "[1.70350000e-05 2.66159443e-04 8.17056023e-04 1.03030082e-05\n",
      " 5.57736672e-04 2.05300587e-03 5.66141088e-04 5.22094089e-04\n",
      " 8.33319101e-05 1.68327694e-05 9.10330147e-05 1.78272409e-04\n",
      " 4.84309714e-03 3.40514427e-03 2.64873591e-04 1.35180765e-03\n",
      " 5.48515509e-03 2.22436934e-04 2.44490062e-04 5.40259701e-03\n",
      " 5.10851195e-03 8.62512061e-03 2.02976836e-02 5.45537910e-03\n",
      " 2.82773707e-04 1.17719748e-02 5.00529949e-04 2.78538753e-04\n",
      " 8.78699206e-06 1.22012453e-03 9.72575315e-03 5.41049596e-03\n",
      " 1.96915569e-02 2.80893753e-03 4.45801945e-03 7.20958342e-04\n",
      " 1.26119549e-05 3.51281871e-03 2.91636439e-03 5.53695715e-03\n",
      " 9.85639124e-04 7.49386657e-03 3.13017095e-02 6.75271616e-04\n",
      " 2.57170841e-03 9.90775419e-04 1.63672158e-02 2.64822522e-03\n",
      " 9.93946378e-03 4.50970681e-03 1.24509000e-03 9.94851362e-05\n",
      " 1.04146489e-02 1.94346094e-02 9.38907969e-03 2.01237495e-02\n",
      " 6.68056696e-03 1.04239468e-04 1.95441342e-02]\n"
     ]
    }
   ],
   "source": [
    "# fisher\n",
    "mean_total_mod = np.mean(mod_freq,axis=1)\n",
    "\n",
    "mean_pos_mod = np.mean(mod_freq[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "mean_neg_mod = np.mean(mod_freq[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "var_pos_mod = np.var(mod_freq[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "var_neg_mod = np.var(mod_freq[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "fisher_mod_freq = fisher1D(mean_total_mod, mean_pos_mod, mean_neg_mod, var_pos_mod, var_neg_mod)\n",
    "\n",
    "print(fisher_mod_freq.shape)\n",
    "\n",
    "print('fisher of Median Frequency feature: \\n')\n",
    "print(fisher_mod_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 159)\n"
     ]
    }
   ],
   "source": [
    "mod_freq_test = weighted_median_frequency(test_data,data_fs)\n",
    "print(mod_freq_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fisher_mod_freq)):\n",
    "    fishersOfFeatures_freq.append([fisher_mod_freq[i],'mod_freq_channel' + str(i), mod_freq[i],mod_freq_test[i]])\n",
    "\n",
    "print(len(fishersOfFeatures_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Relative Energy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_band_energies(data, sampling_rate, bands):\n",
    "    channels, samples, experiments = data.shape\n",
    "\n",
    "    relative_band_energies = np.zeros((channels, experiments, len(bands.keys())))\n",
    "    band_energies = np.zeros((channels, experiments, len(bands.keys())))\n",
    "\n",
    "    for channel in range(channels):\n",
    "        for experiment in range(experiments):\n",
    "            signal = data[channel, :, experiment]\n",
    "            frequencies, psd = periodogram(signal, sampling_rate)\n",
    "            frequencies = frequencies.ravel()\n",
    "\n",
    "            total_energy = 0\n",
    "            for k, (band, (low, high)) in enumerate(bands.items()):\n",
    "                band_energy = 0\n",
    "                for i, freq in enumerate(frequencies):\n",
    "                    if (low <= freq) and (freq < high):\n",
    "                        band_energy += psd[i]\n",
    "                # idx_band = np.logical_and(frequencies >= low, frequencies <= high)\n",
    "                # band_energy = simps(psd[idx_band], frequencies[idx_band])\n",
    "                total_energy += band_energy\n",
    "                band_energies[channel, experiment, k] = band_energy\n",
    "            #print(total_energy)\n",
    "            relative_band_energies[channel, experiment, :] = band_energies[channel, experiment, :] / total_energy\n",
    "    \n",
    "    return relative_band_energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "bands = {\n",
    "    'delta': [0.1, 3],\n",
    "    'theta': [4, 7],\n",
    "    'alpha': [8, 12],\n",
    "    'low_range_beta': [12, 15],\n",
    "    'mid_range_beta': [16, 20],\n",
    "    'high_range_beta': [21, 30],\n",
    "    'gamma': [30, 100]\n",
    "}\n",
    "\n",
    "bands2 = {\n",
    "    'theta': [4, 8],\n",
    "    'alpha': [8, 13],\n",
    "    'beta': [13, 30],\n",
    "    'gamma': [30, 49],\n",
    "}\n",
    "\n",
    "relative_band_energies = calculate_relative_band_energies(training_data, data_fs, bands2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 550, 4)\n"
     ]
    }
   ],
   "source": [
    "print(relative_band_energies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 4)\n",
      "fisher of Relative Band Energies feature: \n",
      "\n",
      "theta:\n",
      "\n",
      "[2.04990726e-04 2.77638387e-03 5.65286397e-05 1.00647150e-03\n",
      " 3.38405292e-03 4.20832211e-03 1.38152897e-03 1.13261368e-03\n",
      " 3.34775812e-05 5.34870001e-03 1.17443235e-04 1.25841696e-03\n",
      " 7.75541728e-03 3.30837852e-04 4.29195252e-03 2.28281959e-04\n",
      " 9.92353460e-03 6.79822145e-04 7.64690613e-03 4.28266601e-03\n",
      " 7.99432578e-04 2.21006690e-03 2.47960593e-02 5.99876581e-03\n",
      " 7.15064029e-03 5.31548193e-03 2.71210686e-03 4.37206906e-03\n",
      " 4.43538668e-04 3.29791344e-05 1.13148223e-02 1.03293511e-02\n",
      " 1.12782376e-02 1.08728454e-02 1.64732741e-03 2.05692241e-03\n",
      " 4.77074373e-05 8.69449889e-04 5.09948088e-03 9.04204938e-03\n",
      " 6.34475131e-03 1.63645632e-02 1.40027700e-03 8.87825355e-06\n",
      " 6.24138735e-04 2.50192581e-03 1.13956253e-02 8.99459433e-03\n",
      " 1.34320277e-02 3.58258866e-02 6.68065033e-03 1.73407485e-02\n",
      " 7.70425354e-03 9.48050085e-03 9.98689703e-03 1.17017396e-02\n",
      " 3.56726767e-02 7.80340334e-03 2.54916964e-02] 4\n",
      "\n",
      " alpha \n",
      "\n",
      "[1.39490121e-03 2.62251980e-03 1.56231645e-07 8.35468154e-04\n",
      " 1.18093470e-03 8.07067043e-05 1.84187625e-03 6.89860783e-04\n",
      " 5.47575285e-05 6.61901946e-04 6.24932937e-05 1.13161410e-04\n",
      " 1.28347839e-03 7.57248417e-04 2.85588604e-04 2.78169680e-04\n",
      " 7.43110996e-03 3.19597542e-03 7.97678897e-03 1.85525375e-03\n",
      " 6.81324763e-03 2.98026581e-03 7.17374943e-03 3.28493759e-03\n",
      " 2.70111112e-03 1.03069786e-02 4.18456096e-03 9.32471488e-03\n",
      " 2.13588828e-03 4.84610802e-03 4.75700706e-03 5.09545465e-03\n",
      " 5.04179979e-03 1.65232953e-03 2.89302484e-03 8.82662768e-03\n",
      " 3.14681232e-03 3.02982628e-03 1.73781335e-03 3.43918757e-03\n",
      " 3.15812510e-03 3.46221556e-03 7.72743186e-03 3.51747334e-03\n",
      " 4.71085947e-03 8.01391689e-04 4.49608078e-03 1.70529184e-03\n",
      " 4.27875999e-03 1.26599101e-04 8.17382357e-04 9.67486679e-04\n",
      " 3.89552117e-03 4.23079292e-03 2.82491547e-03 5.41195359e-03\n",
      " 3.78701245e-05 4.53101518e-07 6.65874720e-03] 4\n"
     ]
    }
   ],
   "source": [
    "mean_total_bands = np.mean(relative_band_energies, axis=1)\n",
    "\n",
    "mean_pos_bands = np.mean(relative_band_energies[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "mean_neg_bands = np.mean(relative_band_energies[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "var_pos_bands = np.var(relative_band_energies[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "var_neg_bands = np.var(relative_band_energies[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "fishers_of_bands = fisher1D(mean_total_bands,mean_pos_bands,mean_neg_bands,var_pos_bands,var_neg_bands)\n",
    "\n",
    "print(fishers_of_bands.shape)\n",
    "print('fisher of Relative Band Energies feature: \\n')\n",
    "print('theta:\\n')\n",
    "print(fishers_of_bands[:,0],4)\n",
    "print('\\n alpha \\n')\n",
    "print(fishers_of_bands[:,1],4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta \n",
      "\n",
      "[1.04491625e-03 3.91718961e-03 2.90566667e-06 4.49437385e-03\n",
      " 4.21931273e-03 3.31507947e-04 6.52252275e-03 4.17220737e-04\n",
      " 3.05606908e-05 2.54709614e-03 3.43327176e-04 1.72036371e-03\n",
      " 4.29275005e-03 4.61738909e-05 2.13617726e-03 4.37921632e-04\n",
      " 2.43834575e-05 3.54495995e-04 4.63620367e-04 1.59339213e-03\n",
      " 2.28839324e-03 2.33099141e-03 1.28032098e-02 4.81051792e-03\n",
      " 8.23807883e-03 4.63251722e-03 2.10473362e-03 5.47836938e-03\n",
      " 2.60365500e-03 6.82453791e-03 5.01067120e-03 1.05156908e-02\n",
      " 9.18372660e-04 7.32026066e-03 2.43773347e-03 7.59116589e-03\n",
      " 1.85380839e-03 5.89063337e-03 1.18901875e-03 7.77085630e-03\n",
      " 1.46203068e-02 6.08266594e-03 1.49195269e-02 5.34393390e-04\n",
      " 4.56079525e-03 2.07909127e-04 3.60760213e-03 2.12751028e-03\n",
      " 5.47183011e-03 1.46954054e-02 9.00865743e-03 1.23421875e-02\n",
      " 2.98743664e-03 2.33028868e-03 4.99177250e-03 3.19589326e-03\n",
      " 1.45837396e-02 8.33019152e-05 7.25625283e-03] 4\n",
      "\n",
      " gamma \n",
      "\n",
      "[1.79062119e-04 2.79029471e-04 6.01604128e-05 1.46856990e-04\n",
      " 1.51750836e-03 7.97602519e-04 6.95354778e-05 1.34262548e-05\n",
      " 2.67603382e-05 1.56185286e-04 7.23299341e-04 9.68837665e-05\n",
      " 3.38244655e-03 9.56503499e-04 1.19195341e-03 2.22781055e-04\n",
      " 1.29058714e-03 7.20127607e-04 2.92413066e-04 4.27756839e-03\n",
      " 2.09681358e-03 3.14314482e-03 1.86444158e-02 4.32413449e-03\n",
      " 3.28756492e-03 3.88827986e-03 1.59255107e-03 3.45156054e-03\n",
      " 3.53941902e-03 3.66616361e-03 1.09918912e-02 9.86867610e-03\n",
      " 1.70842876e-02 6.04618948e-03 6.14555581e-04 7.94730358e-03\n",
      " 5.05140638e-03 4.84166883e-03 6.16585746e-03 1.21501037e-02\n",
      " 2.25830953e-03 1.81310451e-02 2.17726142e-03 9.29516689e-03\n",
      " 8.41621085e-03 4.02963831e-03 1.32061760e-02 6.34891565e-03\n",
      " 1.59328159e-02 2.49349228e-02 3.50477113e-03 1.10683672e-02\n",
      " 1.00083700e-02 1.53574319e-02 6.90770947e-03 1.74427919e-02\n",
      " 1.06762423e-02 1.76325722e-03 2.56962747e-02] 4\n"
     ]
    }
   ],
   "source": [
    "print('beta \\n')\n",
    "print(fishers_of_bands[:,2],4)\n",
    "print('\\n gamma \\n')\n",
    "print(fishers_of_bands[:,3],4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 159, 4)\n"
     ]
    }
   ],
   "source": [
    "relative_band_energies_test = calculate_relative_band_energies(test_data, data_fs, bands2)\n",
    "print(relative_band_energies_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413\n"
     ]
    }
   ],
   "source": [
    "for i in range(fishers_of_bands.shape[0]):\n",
    "        fishersOfFeatures_freq.append([fishers_of_bands[i,0],'band_theta_channel' + str(i), relative_band_energies[i,:,0],relative_band_energies_test[i,:,0]])\n",
    "        fishersOfFeatures_freq.append([fishers_of_bands[i,1],'band_alpha_channel' + str(i), relative_band_energies[i,:,1], relative_band_energies_test[i,:,1]])\n",
    "        fishersOfFeatures_freq.append([fishers_of_bands[i,2],'band_beta_channel' + str(i), relative_band_energies[i,:,2], relative_band_energies_test[i,:,2]])\n",
    "        fishersOfFeatures_freq.append([fishers_of_bands[i,3],'band_gamma_channel' + str(i), relative_band_energies[i,:,3], relative_band_energies_test[i,:,3]])\n",
    "        \n",
    "print(len(fishersOfFeatures_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Statistical features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishersOfFeatures_stat=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Variance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 550)\n"
     ]
    }
   ],
   "source": [
    "# function\n",
    "def calc_variance(data):\n",
    "    return np.var(data, axis=1)\n",
    "\n",
    "\n",
    "variance = calc_variance(training_data)\n",
    "print(variance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59,)\n",
      "fisher of variance feature: \n",
      "\n",
      "[1.52394156e-06 1.73079774e-03 3.20643248e-03 8.81358431e-04\n",
      " 6.06595201e-03 1.02018027e-02 1.04566148e-02 1.78090820e-03\n",
      " 3.81505106e-03 7.37470031e-03 1.56928825e-03 4.83497522e-03\n",
      " 1.32857437e-02 2.68406128e-03 1.24992780e-02 5.32735097e-03\n",
      " 1.96545579e-03 3.94847633e-03 3.51609845e-03 2.97559573e-03\n",
      " 1.79632502e-03 2.43538807e-04 3.38514735e-03 2.37443284e-03\n",
      " 3.59120962e-03 8.35729020e-03 2.48960766e-03 3.75756308e-03\n",
      " 2.11889684e-03 1.22284553e-03 3.24048063e-05 1.74225079e-03\n",
      " 4.93023939e-03 2.98817088e-03 9.18157757e-03 8.53321215e-03\n",
      " 4.77973271e-03 1.89556030e-03 7.63670189e-04 1.84095545e-04\n",
      " 9.01492585e-04 4.02095217e-03 1.56557017e-02 6.87409816e-03\n",
      " 1.58501039e-03 6.25736519e-03 1.38436511e-03 4.39152291e-03\n",
      " 1.07094719e-04 1.07304448e-02 2.57599852e-03 5.31913495e-03\n",
      " 1.12529830e-02 7.20925516e-08 4.74217456e-03 6.59729072e-05\n",
      " 6.88301200e-03 5.03835631e-04 1.01854443e-03]\n"
     ]
    }
   ],
   "source": [
    "# fisher\n",
    "mean_total_var = np.mean(variance,axis=1)\n",
    "\n",
    "mean_pos_var = np.mean(variance[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "mean_neg_var = np.mean(variance[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "var_pos_var = np.var(variance[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "var_neg_var = np.var(variance[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "fisher_var = fisher1D(mean_total_var, mean_pos_var, mean_neg_var, var_pos_var, var_neg_var)\n",
    "\n",
    "print(fisher_var.shape)\n",
    "print('fisher of variance feature: \\n')\n",
    "print(fisher_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 159)\n"
     ]
    }
   ],
   "source": [
    "variance_test = calc_variance(test_data)\n",
    "print(variance_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fisher_var)):\n",
    "    fishersOfFeatures_stat.append([fisher_var[i],'var_channel' + str(i), variance[i], variance_test[i]])\n",
    "\n",
    "print(len(fishersOfFeatures_stat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Domain Histogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_domain_histogram(data, num_bins):\n",
    "    channels, samples, experiments = data.shape\n",
    "    \n",
    "    domain_histograms = np.zeros((channels, num_bins, experiments))\n",
    "    \n",
    "    for channel in range(channels):\n",
    "        for experiment in range(experiments):     \n",
    "\n",
    "            hist, bin_edges = np.histogram(data[channel, :, experiment], bins=num_bins)\n",
    "            domain_histograms[channel, :, experiment] = hist\n",
    "\n",
    "    return domain_histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 10, 550)\n"
     ]
    }
   ],
   "source": [
    "#result\n",
    "domain_histogram = calc_domain_histogram(training_data,10)\n",
    "print(domain_histogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 10)\n",
      "fisher of Domain Histogram feature: \n",
      "\n",
      "[[1.29935616e-02 9.81471574e-03 8.45622597e-03 5.21142527e-03\n",
      "  3.72736191e-03 4.77256752e-03 6.81283913e-03 6.42069127e-03\n",
      "  1.17336169e-02 1.19115927e-02]\n",
      " [2.21520998e-03 5.80796635e-03 7.50476161e-03 5.57822087e-03\n",
      "  1.10114621e-03 5.30350044e-03 4.48305929e-03 3.12714166e-03\n",
      "  3.00753607e-04 2.32287666e-04]\n",
      " [3.41007136e-03 9.02866637e-04 5.06643494e-05 1.09266894e-04\n",
      "  9.28768631e-04 3.17958325e-03 3.10195645e-07 2.67175617e-03\n",
      "  1.41378965e-03 3.51405462e-04]\n",
      " [5.66002181e-03 1.85408776e-08 9.78699669e-04 3.96401741e-03\n",
      "  5.56655807e-03 2.70805846e-03 2.67844913e-03 2.76696715e-03\n",
      "  2.91934029e-03 2.64540762e-03]\n",
      " [6.12088463e-05 6.47421414e-05 5.34258147e-04 4.40140542e-04\n",
      "  4.91806137e-04 3.21722314e-03 1.01221586e-04 2.49638245e-04\n",
      "  5.14710976e-05 4.13962237e-03]\n",
      " [1.25790667e-03 6.71163387e-03 7.87017357e-03 2.08864281e-03\n",
      "  2.64534292e-04 8.97068129e-05 2.20842757e-03 4.24566770e-03\n",
      "  4.07850965e-03 8.13954764e-04]\n",
      " [1.08914669e-02 6.14101640e-03 2.78723225e-03 2.04339459e-03\n",
      "  1.61684596e-03 2.87286067e-04 2.88196197e-03 4.95365745e-03\n",
      "  1.82426212e-03 3.54509342e-04]\n",
      " [1.18435618e-06 6.05467247e-04 8.31647218e-05 3.58517804e-06\n",
      "  3.75644544e-06 9.17655070e-05 6.13589193e-05 1.66273760e-04\n",
      "  7.39710042e-05 4.18112210e-03]\n",
      " [1.09831040e-03 1.28769594e-02 2.37425667e-02 1.99458229e-02\n",
      "  1.45362146e-03 1.79099143e-02 1.93588205e-02 1.07460242e-02\n",
      "  5.80068850e-03 3.03668304e-03]\n",
      " [9.94910540e-04 7.18264589e-04 1.33369711e-03 8.53261866e-05\n",
      "  6.03110991e-04 9.84705755e-04 2.80343912e-06 1.42803587e-05\n",
      "  1.66906035e-05 6.69229729e-06]\n",
      " [7.33745399e-03 2.08855142e-02 3.24002990e-02 1.91626260e-02\n",
      "  3.09670566e-03 2.50597879e-02 1.54737195e-02 9.86549501e-03\n",
      "  2.96959126e-03 1.79971349e-03]\n",
      " [7.95078517e-04 2.57155361e-03 3.18807514e-03 4.23312895e-04\n",
      "  4.18855055e-04 7.42287198e-04 1.79591285e-03 4.37238166e-03\n",
      "  2.93243342e-03 3.54700310e-03]\n",
      " [7.88924159e-03 1.58495002e-04 1.14480669e-03 3.88911980e-03\n",
      "  1.60373095e-03 5.31699982e-04 4.26856377e-03 7.44775978e-03\n",
      "  6.91499304e-03 7.66930158e-03]\n",
      " [1.07928560e-03 3.66959812e-04 1.47985346e-05 5.09704863e-05\n",
      "  9.29757805e-05 5.17692919e-07 2.01134622e-05 8.58314145e-06\n",
      "  5.44916745e-04 2.85868941e-03]\n",
      " [3.90900008e-04 2.99531735e-04 9.35648368e-05 1.14113828e-03\n",
      "  6.20442275e-04 9.43013308e-04 2.61332473e-04 2.67865228e-03\n",
      "  2.47776240e-03 7.29366582e-04]\n",
      " [2.83767379e-04 1.84287813e-03 7.92195171e-04 5.55099356e-03\n",
      "  4.36010778e-03 2.94212639e-04 3.98778153e-03 3.30766211e-03\n",
      "  1.54329948e-03 3.72315446e-04]\n",
      " [2.69004924e-04 2.68123044e-03 3.80309781e-03 2.58118549e-03\n",
      "  1.03039974e-03 1.68784621e-03 4.72174983e-03 1.12281664e-03\n",
      "  1.88343716e-03 5.44170719e-03]\n",
      " [9.63254253e-03 7.90793137e-03 1.00612014e-02 4.28039827e-03\n",
      "  5.26865928e-03 1.58292243e-02 1.17976463e-03 1.06740087e-04\n",
      "  2.26938830e-03 3.18346170e-03]\n",
      " [1.01515439e-02 1.45521914e-03 7.40173973e-04 2.86641951e-04\n",
      "  3.63161243e-03 2.51898818e-05 1.11391948e-04 1.50094683e-04\n",
      "  2.00601104e-04 7.89973019e-07]\n",
      " [1.05119097e-02 8.78064859e-03 1.41187595e-02 2.57241084e-02\n",
      "  6.37772214e-03 2.31806158e-02 2.35698285e-02 1.57468569e-02\n",
      "  1.22562633e-02 8.34657406e-03]\n",
      " [5.15905526e-03 5.34349119e-03 3.37376324e-03 1.47892103e-03\n",
      "  2.88675675e-05 1.48968755e-04 3.13331379e-03 2.80149035e-03\n",
      "  2.33985489e-03 3.38670732e-03]\n",
      " [8.24305585e-04 3.46967701e-04 1.01343710e-04 3.81942507e-04\n",
      "  2.00671161e-06 1.51135667e-05 7.96351776e-05 1.80376588e-04\n",
      "  5.77191109e-04 2.99365256e-03]\n",
      " [1.65193973e-03 4.88616916e-03 3.51842774e-03 7.50167232e-03\n",
      "  1.64138587e-03 3.97550799e-03 8.63782573e-03 3.19803828e-03\n",
      "  1.36138674e-03 5.60522263e-04]\n",
      " [3.37966815e-03 7.91082504e-03 1.04827610e-02 6.87156041e-03\n",
      "  4.11565591e-03 3.50128680e-03 6.41329914e-03 6.10728952e-03\n",
      "  1.69655987e-03 4.42430613e-04]\n",
      " [7.19650534e-04 9.60587971e-04 3.74292268e-03 6.76851133e-03\n",
      "  1.66418790e-02 1.43433651e-03 1.15202801e-02 1.40315322e-02\n",
      "  9.66607829e-03 4.36386667e-03]\n",
      " [1.10725550e-03 6.26867098e-04 1.96844981e-04 3.29636922e-06\n",
      "  7.55157014e-04 1.19779582e-03 3.98686018e-04 2.19099907e-03\n",
      "  2.03211385e-03 6.43548917e-04]\n",
      " [6.87064242e-03 7.69356474e-03 4.28241838e-03 1.94774564e-03\n",
      "  7.78826819e-04 6.57066966e-03 4.55263809e-03 1.31517211e-04\n",
      "  6.87430344e-05 1.91801142e-04]\n",
      " [4.00655562e-04 2.74226699e-03 3.82241683e-03 2.65251062e-03\n",
      "  2.16915770e-04 7.22950207e-03 2.55988619e-03 2.86871940e-06\n",
      "  8.03816029e-05 2.12435584e-05]\n",
      " [2.44604979e-04 6.41299268e-04 5.15764290e-04 3.44687853e-05\n",
      "  1.42427922e-03 1.17347666e-03 7.98523297e-06 7.07576252e-04\n",
      "  3.69175207e-04 7.55244019e-06]\n",
      " [4.33367286e-06 5.00260336e-04 1.01617442e-06 3.10407436e-04\n",
      "  2.37450093e-04 5.50125616e-05 6.75750868e-06 2.71468236e-05\n",
      "  6.70193256e-05 1.36744032e-03]\n",
      " [1.24040914e-04 9.04481623e-03 8.52472637e-03 5.48390184e-03\n",
      "  2.39719074e-03 7.03006617e-03 7.94151115e-03 2.33560602e-03\n",
      "  1.02548748e-03 1.22810561e-03]\n",
      " [4.02687128e-05 2.76355130e-05 5.06024070e-04 8.32073420e-04\n",
      "  4.37474755e-04 1.76957857e-03 6.84965427e-04 1.11215311e-04\n",
      "  1.33781776e-04 5.29794729e-04]\n",
      " [1.81823070e-03 4.37272103e-05 2.29166030e-04 1.95716887e-04\n",
      "  2.48727671e-03 1.94235559e-05 5.12851165e-04 4.14578886e-04\n",
      "  1.76160412e-04 4.31223239e-04]\n",
      " [1.33811049e-02 2.14086497e-03 7.84002265e-05 5.14830259e-04\n",
      "  1.65822634e-04 2.78575836e-03 3.40563868e-05 7.98690768e-04\n",
      "  3.75731013e-03 4.86702720e-04]\n",
      " [9.50208047e-06 5.99089242e-04 5.45652089e-05 2.17163450e-04\n",
      "  4.65501995e-04 5.83848375e-04 9.10909848e-05 2.55729962e-03\n",
      "  4.22922339e-03 1.36904610e-03]\n",
      " [4.21983496e-03 9.86645547e-03 1.40779085e-02 6.83904488e-03\n",
      "  5.27760565e-04 1.18676732e-02 6.83562296e-03 2.15665975e-03\n",
      "  1.91445273e-07 1.86149671e-03]\n",
      " [2.96485949e-03 5.24152369e-03 3.38600841e-03 3.29908219e-03\n",
      "  3.43881020e-05 1.11740451e-02 1.29054378e-03 1.16322172e-04\n",
      "  5.16597469e-05 2.10222250e-03]\n",
      " [2.94514740e-03 1.40389060e-02 1.28355279e-02 7.51218427e-03\n",
      "  3.31970229e-03 5.97424948e-03 9.30653839e-03 5.09873656e-03\n",
      "  3.74609443e-03 1.01667801e-02]\n",
      " [4.18312190e-05 2.20575905e-03 4.48706507e-03 9.91550939e-04\n",
      "  1.89547418e-04 5.39511563e-04 6.23966851e-05 6.96248549e-04\n",
      "  2.35838773e-04 4.24481115e-05]\n",
      " [6.91471073e-04 4.38189442e-04 1.55363064e-03 6.53851689e-04\n",
      "  7.68696820e-05 9.63973596e-04 1.18610106e-03 1.89172864e-05\n",
      "  5.18596891e-06 2.61044057e-04]\n",
      " [2.72503134e-04 4.97321614e-03 8.79279007e-03 7.54968228e-03\n",
      "  3.57951459e-03 5.67695154e-04 6.18868958e-03 6.62984445e-03\n",
      "  6.06492964e-03 1.54356284e-03]\n",
      " [1.31513800e-03 2.24065965e-03 3.24776372e-03 3.15103991e-03\n",
      "  5.91088666e-05 2.26690307e-03 2.93699268e-03 4.30429025e-04\n",
      "  2.63838173e-04 5.58401132e-06]\n",
      " [1.13261837e-03 4.95807132e-04 9.55650878e-04 1.31385455e-03\n",
      "  2.78497086e-04 3.85883563e-05 1.14062046e-03 2.35936895e-03\n",
      "  1.75351608e-03 1.75091580e-03]\n",
      " [4.07756430e-04 2.36081824e-03 1.21181367e-03 2.99202768e-05\n",
      "  3.87748228e-03 3.60959943e-03 1.57981542e-04 3.79079657e-03\n",
      "  9.55997526e-04 5.36466908e-05]\n",
      " [2.34862975e-03 3.01189988e-03 3.33381678e-03 6.83506039e-05\n",
      "  8.24401371e-03 3.02648329e-03 1.30920774e-04 2.52930306e-03\n",
      "  3.05011113e-03 8.22405052e-04]\n",
      " [1.80168738e-03 4.83943705e-05 1.54612379e-05 4.80564102e-04\n",
      "  7.17694305e-03 5.39405576e-05 2.93513312e-03 4.91101667e-03\n",
      "  2.24342630e-03 1.28834040e-03]\n",
      " [6.07519612e-04 1.30580460e-04 3.16725460e-03 4.52738271e-03\n",
      "  2.59324215e-04 1.33311466e-03 9.75615608e-04 6.44219897e-04\n",
      "  1.15926465e-03 1.27258367e-03]\n",
      " [2.45148706e-05 5.01576050e-05 1.38703167e-04 3.90409074e-03\n",
      "  6.86610614e-03 2.80597753e-05 5.73885732e-03 7.52186542e-03\n",
      "  3.70000834e-03 2.60626796e-03]\n",
      " [6.86482383e-03 9.21487990e-03 2.06468295e-02 2.40055379e-02\n",
      "  1.08412995e-02 1.41043006e-02 2.19683307e-02 9.89941672e-03\n",
      "  7.32052493e-03 4.63050518e-03]\n",
      " [2.51345505e-03 1.74767706e-03 1.63804566e-03 6.98914616e-04\n",
      "  5.47765773e-03 1.12517927e-03 2.87069937e-03 3.76392822e-03\n",
      "  3.95378249e-03 2.05568793e-04]\n",
      " [4.59026836e-03 1.56781380e-05 4.19552027e-04 5.18489252e-04\n",
      "  4.85205255e-04 8.51333369e-04 9.10413267e-04 5.06562272e-03\n",
      "  3.05230611e-03 5.09953713e-05]\n",
      " [3.05004614e-03 6.53054277e-04 3.10254882e-03 4.52562776e-03\n",
      "  3.52421327e-03 2.93928829e-03 4.93322986e-03 5.65839443e-03\n",
      "  1.28004380e-03 1.45740503e-03]\n",
      " [4.45359912e-03 1.92872962e-03 3.38895795e-04 3.01881325e-03\n",
      "  2.57095452e-03 4.78897474e-03 5.48467508e-04 1.06265322e-04\n",
      "  4.54546339e-04 4.43298684e-04]\n",
      " [4.44798614e-05 1.36320537e-03 8.78700194e-03 6.48553768e-03\n",
      "  4.59380534e-04 5.67001807e-03 1.89444325e-03 2.14549335e-03\n",
      "  3.75311930e-03 6.43665033e-03]\n",
      " [9.07654939e-04 2.18778808e-04 2.39572359e-04 1.21553977e-03\n",
      "  1.77318934e-03 3.68636788e-03 1.07285582e-03 1.54399179e-04\n",
      "  9.29716374e-04 3.06488144e-03]\n",
      " [3.30369523e-03 4.85847868e-04 2.91583029e-04 2.73257727e-03\n",
      "  5.18947956e-04 5.23986783e-03 5.51544734e-05 3.37439149e-04\n",
      "  2.25996406e-04 4.35065880e-04]\n",
      " [8.76824283e-04 4.68943008e-03 3.51078364e-03 2.86961629e-03\n",
      "  1.37222734e-05 2.62434739e-03 3.18980801e-03 2.26918070e-03\n",
      "  4.15813852e-03 2.38996538e-03]\n",
      " [4.60841136e-05 2.70452449e-04 1.73655365e-03 4.02909941e-03\n",
      "  1.47826307e-03 6.06865698e-03 2.93689418e-03 5.06997274e-05\n",
      "  3.59451563e-05 2.08107372e-04]\n",
      " [1.41885961e-04 8.85527628e-04 4.56948362e-04 2.55379951e-03\n",
      "  2.22578415e-03 3.57696144e-03 2.61467990e-05 4.56508099e-04\n",
      "  1.26081138e-04 1.46979916e-03]]\n"
     ]
    }
   ],
   "source": [
    "# fisher\n",
    "mean_total_hist = np.mean(domain_histogram, axis=2)\n",
    "\n",
    "mean_pos_hist = np.mean(domain_histogram[:,:, training_data_labels[0,:] == 1],axis = 2)\n",
    "mean_neg_hist = np.mean(domain_histogram[:,:, training_data_labels[0,:] == -1],axis = 2)\n",
    "\n",
    "var_pos_hist = np.var(domain_histogram[:,:, training_data_labels[0,:] == 1],axis = 2)\n",
    "var_neg_hist = np.var(domain_histogram[:,:, training_data_labels[0,:] == -1],axis = 2)\n",
    "\n",
    "fishers_of_hist = fisher1D(mean_total_hist,mean_pos_hist,mean_neg_hist,var_pos_hist,var_neg_hist)\n",
    "\n",
    "print(fishers_of_hist.shape)\n",
    "print('fisher of Domain Histogram feature: \\n')\n",
    "print(fishers_of_hist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 10, 159)\n"
     ]
    }
   ],
   "source": [
    "domain_histogram_test = calc_domain_histogram(test_data,10)\n",
    "print(domain_histogram_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(fishers_of_hist.shape[0]):\n",
    "    for j in range(fishers_of_hist.shape[1]):\n",
    "        fishersOfFeatures_stat.append([fishers_of_hist[i,j],'hist' + str(j) +'_channel'+ str(i) , domain_histogram[i,j,:], domain_histogram_test[i,j,:]])\n",
    "\n",
    "print(len(fishersOfFeatures_stat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Form Factor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def calc_form_factor(data, sampling_rate):\n",
    "    channels, samples, experiments = data.shape\n",
    "    \n",
    "    form_factors = np.zeros((channels, experiments))\n",
    "    \n",
    "    for channel in range(channels):\n",
    "        for experiment in range(experiments):\n",
    "        \n",
    "            first_derivative = np.diff(data[channel, :, experiment])\n",
    "            second_derivative = np.diff(first_derivative)\n",
    "            \n",
    "            std_signal = np.std(data[channel, :, experiment])\n",
    "            std_first_derivative = np.std(first_derivative)\n",
    "            std_second_derivative = np.std(second_derivative)\n",
    "\n",
    "            ff = (std_second_derivative/std_first_derivative) / (std_first_derivative/std_signal)\n",
    "            form_factors[channel, experiment] = ff\n",
    "\n",
    "    return form_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 550)\n"
     ]
    }
   ],
   "source": [
    "#result\n",
    "form_factor = calc_form_factor(training_data,data_fs)\n",
    "print(form_factor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59,)\n",
      "fisher of Form Factor feature: \n",
      "\n",
      "[2.28544002e-03 6.92775439e-04 5.00181169e-03 5.35410609e-04\n",
      " 4.14559108e-04 2.71237855e-03 3.71384662e-04 7.63962990e-04\n",
      " 7.80301283e-04 1.01016260e-04 5.50472538e-04 1.59748306e-05\n",
      " 2.02963280e-03 1.60409035e-03 2.46702009e-04 6.36300726e-04\n",
      " 1.98757238e-03 3.31860399e-05 1.99154294e-07 2.56081809e-04\n",
      " 4.28873683e-05 5.61049448e-05 5.32897358e-03 4.55814741e-04\n",
      " 2.05462411e-03 3.43034644e-03 6.63825440e-06 4.19425312e-05\n",
      " 5.89605538e-07 1.74044674e-04 1.39326582e-03 2.57610482e-03\n",
      " 6.26591048e-04 3.52371702e-03 2.58499065e-05 1.72514827e-03\n",
      " 1.81088751e-03 2.45200995e-04 1.23967384e-03 1.64874448e-03\n",
      " 2.44408568e-03 2.91331317e-03 3.78839489e-05 5.38698204e-04\n",
      " 4.83917553e-05 8.48486094e-04 5.13522637e-04 8.97840336e-04\n",
      " 1.82945719e-03 4.57830968e-04 9.51722663e-04 5.59180770e-04\n",
      " 1.18403323e-03 5.31050728e-04 1.08461162e-05 6.45300913e-04\n",
      " 1.96620706e-06 1.46144732e-03 4.88225932e-03]\n"
     ]
    }
   ],
   "source": [
    "# fisher\n",
    "mean_total_ff = np.mean(form_factor,axis=1)\n",
    "\n",
    "mean_pos_ff = np.mean(form_factor[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "mean_neg_ff = np.mean(form_factor[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "var_pos_ff = np.var(form_factor[:, training_data_labels[0,:] == 1],axis = 1)\n",
    "var_neg_ff = np.var(form_factor[:, training_data_labels[0,:] == -1],axis = 1)\n",
    "\n",
    "fisher_ff = fisher1D(mean_total_ff, mean_pos_ff, mean_neg_ff, var_pos_ff, var_neg_ff)\n",
    "\n",
    "print(fisher_ff.shape)\n",
    "print('fisher of Form Factor feature: \\n')\n",
    "print(fisher_ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 159)\n"
     ]
    }
   ],
   "source": [
    "form_factor_test = calc_form_factor(test_data,data_fs)\n",
    "print(form_factor_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fisher_ff)):\n",
    "    fishersOfFeatures_stat.append([fisher_ff[i],'ff_channel' + str(i), form_factor[i], form_factor_test[i]])\n",
    "\n",
    "print(len(fishersOfFeatures_stat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def calc_correlation(data):\n",
    "    channels, samples, experiments = data.shape\n",
    "    correlations = np.zeros((channels, channels, experiments))\n",
    "\n",
    "    for experiment in range(experiments):\n",
    "        for i in range(channels):\n",
    "            for j in range(i+1, channels):\n",
    "                \n",
    "                # Calculate the correlation coefficient between signals i and j\n",
    "                correlation_coefficient = np.corrcoef(data[i, :, experiment], data[j, :, experiment])[0, 1]\n",
    "                correlations[i, j, experiment] = correlation_coefficient\n",
    "\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 59, 550)\n"
     ]
    }
   ],
   "source": [
    "# result\n",
    "correlation_matrices = calc_correlation(training_data)\n",
    "print(correlation_matrices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 59, 159)\n"
     ]
    }
   ],
   "source": [
    "correlation_matrices_test = calc_correlation(test_data)\n",
    "print(correlation_matrices_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 59)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/6xdwk4ls5nb4d1hy_mlzx5380000gn/T/ipykernel_2141/2606028922.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  return sb/sw\n"
     ]
    }
   ],
   "source": [
    "# fisher\n",
    "mean_total_corr = np.mean(correlation_matrices, axis=2)\n",
    "\n",
    "mean_pos_corr = np.mean(correlation_matrices[:,:, training_data_labels[0,:] == 1],axis = 2)\n",
    "mean_neg_corr = np.mean(correlation_matrices[:,:, training_data_labels[0,:] == -1],axis = 2)\n",
    "\n",
    "var_pos_corr = np.var(correlation_matrices[:,:, training_data_labels[0,:] == 1],axis = 2)\n",
    "var_neg_corr = np.var(correlation_matrices[:,:, training_data_labels[0,:] == -1],axis = 2)\n",
    "\n",
    "matrix_fishers_of_corr = fisher1D(mean_total_corr, mean_pos_corr, mean_neg_corr, var_pos_corr, var_neg_corr)\n",
    "\n",
    "print(matrix_fishers_of_corr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2419\n"
     ]
    }
   ],
   "source": [
    "for i in range(59):\n",
    "    for j in range(i+1, 59):\n",
    "        fishersOfFeatures_stat.append([matrix_fishers_of_corr[i,j], 'corr_'+'channel'+str(i)+'channel'+str(j), correlation_matrices[i,j,:], correlation_matrices_test[i,j,:]])\n",
    "\n",
    "print(len(fishersOfFeatures_stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2419\n"
     ]
    }
   ],
   "source": [
    "print(len(fishersOfFeatures_stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2832\n"
     ]
    }
   ],
   "source": [
    "#combining fishers of freq and fishers of stat\n",
    "fishersOfFeatures = fishersOfFeatures_freq + fishersOfFeatures_stat\n",
    "print(len(fishersOfFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *MLP*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extracting 50 best features according to Fisher method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 550)\n",
      "(50, 159)\n",
      "['band_theta_channel49', 'band_theta_channel56', 'hist2_channel10', 'mod_freq_channel42', 'hist3_channel19', 'band_gamma_channel58', 'band_theta_channel58', 'hist5_channel10', 'band_gamma_channel49', 'band_theta_channel22', 'mean_freq_channel22', 'hist3_channel48', 'max_freq_channel23', 'hist2_channel8', 'hist6_channel19', 'max_freq_channel42', 'hist5_channel19', 'max_freq_channel22', 'corr_channel38channel58', 'hist6_channel48', 'hist1_channel10', 'hist2_channel48', 'corr_channel47channel51', 'corr_channel41channel55', 'mod_freq_channel22', 'corr_channel36channel58', 'mod_freq_channel55', 'hist3_channel8', 'mod_freq_channel32', 'mod_freq_channel58', 'mod_freq_channel53', 'hist6_channel8', 'hist3_channel10', 'mean_freq_channel32', 'band_gamma_channel22', 'corr_channel12channel52', 'band_gamma_channel41', 'corr_channel34channel57', 'mean_freq_channel58', 'hist5_channel8', 'band_gamma_channel55', 'band_theta_channel51', 'max_freq_channel53', 'band_gamma_channel32', 'max_freq_channel50', 'hist4_channel24', 'corr_channel22channel24', 'corr_channel38channel51', 'mod_freq_channel46', 'band_theta_channel41']\n"
     ]
    }
   ],
   "source": [
    "#print(type(fishersOfFeatures_freq[0]))\n",
    "number_of_features = 50\n",
    "\n",
    "sorted_Fisher_freq = sorted(fishersOfFeatures, key=lambda x: x[0], reverse=True)\n",
    "best_Fishers = sorted_Fisher_freq[:number_of_features]\n",
    "\n",
    "best_features = []\n",
    "best_features_test = []\n",
    "best_features_names = []\n",
    "\n",
    "for sublist in best_Fishers:\n",
    "    best_features_names.append((sublist[1]))\n",
    "    best_features.append(sublist[2])\n",
    "    best_features_test.append(sublist[3])\n",
    "\n",
    "best_features = np.array(best_features)\n",
    "best_features_test = np.array(best_features_test)\n",
    "\n",
    "\n",
    "print(best_features.shape)\n",
    "print(best_features_test.shape)\n",
    "\n",
    "print(best_features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 550)\n"
     ]
    }
   ],
   "source": [
    "# normalize best features\n",
    "best_features_normalize = min_max_normalize(best_features)\n",
    "best_features_test_normalize = min_max_normalize(best_features_test)\n",
    "print(best_features_normalize.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving different models accuracies and their predicted values\n",
    "all_best_accuracies_MLP = []\n",
    "all_predicted_MLP = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement MLP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: number of layers:1, number of neurons in layers:[32], activation of layers:['relu']\n",
      "4/4 [==============================] - 0s 603us/step\n",
      "4/4 [==============================] - 0s 488us/step\n",
      "4/4 [==============================] - 0s 491us/step\n",
      "4/4 [==============================] - 0s 556us/step\n",
      "4/4 [==============================] - 0s 534us/step\n",
      "Average Cross-Validation Accuracy: 73.09%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 414us/step\n",
      "Parameters: number of layers:2, number of neurons in layers:[64, 32], activation of layers:['relu', 'relu']\n",
      "4/4 [==============================] - 0s 521us/step\n",
      "4/4 [==============================] - 0s 480us/step\n",
      "4/4 [==============================] - 0s 511us/step\n",
      "4/4 [==============================] - 0s 508us/step\n",
      "4/4 [==============================] - 0s 487us/step\n",
      "Average Cross-Validation Accuracy: 79.09%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 406us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[128, 64, 32], activation of layers:['relu', 'relu', 'sigmoid']\n",
      "4/4 [==============================] - 0s 544us/step\n",
      "4/4 [==============================] - 0s 559us/step\n",
      "4/4 [==============================] - 0s 516us/step\n",
      "4/4 [==============================] - 0s 521us/step\n",
      "4/4 [==============================] - 0s 493us/step\n",
      "Average Cross-Validation Accuracy: 90.55%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 445us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[128, 64, 32], activation of layers:['relu', 'relu', 'relu']\n",
      "4/4 [==============================] - 0s 523us/step\n",
      "4/4 [==============================] - 0s 486us/step\n",
      "4/4 [==============================] - 0s 516us/step\n",
      "4/4 [==============================] - 0s 510us/step\n",
      "4/4 [==============================] - 0s 502us/step\n",
      "Average Cross-Validation Accuracy: 90.18%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 501us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[32, 16, 8], activation of layers:['relu', 'relu', 'sigmoid']\n",
      "4/4 [==============================] - 0s 519us/step\n",
      "4/4 [==============================] - 0s 533us/step\n",
      "4/4 [==============================] - 0s 496us/step\n",
      "4/4 [==============================] - 0s 499us/step\n",
      "4/4 [==============================] - 0s 466us/step\n",
      "Average Cross-Validation Accuracy: 82.55%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 482us/step\n",
      "Parameters: number of layers:4, number of neurons in layers:[128, 63, 32, 16], activation of layers:['relu', 'relu', 'relu', 'relu']\n",
      "4/4 [==============================] - 0s 551us/step\n",
      "4/4 [==============================] - 0s 475us/step\n",
      "4/4 [==============================] - 0s 558us/step\n",
      "4/4 [==============================] - 0s 478us/step\n",
      "4/4 [==============================] - 0s 568us/step\n",
      "Average Cross-Validation Accuracy: 91.82%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 486us/step\n",
      "Parameters: number of layers:5, number of neurons in layers:[32, 64, 128, 64, 32], activation of layers:['relu', 'relu', 'relu', 'relu', 'relu']\n",
      "4/4 [==============================] - 0s 599us/step\n",
      "4/4 [==============================] - 0s 504us/step\n",
      "4/4 [==============================] - 0s 523us/step\n",
      "4/4 [==============================] - 0s 553us/step\n",
      "4/4 [==============================] - 0s 550us/step\n",
      "Average Cross-Validation Accuracy: 90.18%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 516us/step\n"
     ]
    }
   ],
   "source": [
    "# train_data: (500, 50), train_labels: (550, 1)\n",
    "train_data = best_features_normalize.T\n",
    "train_labels = training_data_labels.T\n",
    "testing_data = best_features_test_normalize.T\n",
    "\n",
    "# Convert labels from -1 to 0 for compatibility with \"binary_crossentropy\" loss\n",
    "train_labels = (train_labels + 1) / 2\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "parameters = [[1,[32],['relu']],\n",
    "              [2,[64,32],['relu','relu']],\n",
    "              [3,[128,64,32],['relu','relu','sigmoid']],\n",
    "              [3,[128,64,32],['relu','relu','relu']],\n",
    "              [3,[32,16,8],['relu','relu','sigmoid']],\n",
    "              [4,[128,63,32,16],['relu','relu','relu','relu']],\n",
    "              [5,[32,64,128,64,32],['relu','relu','relu','relu','relu']]\n",
    "              ]\n",
    "\n",
    "def create_mlp_model(num_layers, neurons_per_layer, activation):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=neurons_per_layer[0], activation=activation[0], input_dim=train_data.shape[1]))\n",
    "\n",
    "    for i in range(1, num_layers - 1):\n",
    "        model.add(Dense(units=neurons_per_layer[i], activation=activation[i]))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for params in parameters:\n",
    "    fold_accuracies = []\n",
    "    model = create_mlp_model(params[0],params[1],params[2])\n",
    "    print(f'Parameters: number of layers:{params[0]}, number of neurons in layers:{params[1]}, activation of layers:{params[2]}')\n",
    "    for train_index, val_index in kf.split(train_data):\n",
    "        X_train, X_val = train_data[train_index], train_data[val_index]\n",
    "        y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
    "\n",
    "        \n",
    "        model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "        val_predictions = (model.predict(X_val) > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_val, val_predictions)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "    average_accuracy = np.mean(fold_accuracies)\n",
    "    print(f'Average Cross-Validation Accuracy: {average_accuracy * 100:.2f}%')\n",
    "    print('-' * 30)\n",
    "\n",
    "\n",
    "    model.fit(train_data, train_labels, epochs=30, batch_size=32, verbose=0)\n",
    "\n",
    "    test_predict = (model.predict(testing_data) > 0.5).astype(int)\n",
    "\n",
    "    all_best_accuracies_MLP.append(average_accuracy)\n",
    "    all_predicted_MLP.append(test_predict)\n",
    "\n",
    "    if average_accuracy > best_accuracy:\n",
    "        best_accuracy = average_accuracy\n",
    "        best_params = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP Network Configuration:\n",
      "Number of Layers: 4\n",
      "Neurons per Layer: [128, 63, 32, 16]\n",
      "Activation Function: ['relu', 'relu', 'relu', 'relu']\n",
      "Average Cross-Validation Accuracy: 91.82%\n"
     ]
    }
   ],
   "source": [
    "print(f'Best MLP Network Configuration:')\n",
    "print(f'Number of Layers: {best_params[0]}')\n",
    "print(f'Neurons per Layer: {best_params[1]}')\n",
    "print(f'Activation Function: {best_params[2]}')\n",
    "print(f'Average Cross-Validation Accuracy: {best_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(all_best_accuracies_MLP))\n",
    "print(len(all_predicted_MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomly choose 50 features from 75 best featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Random Selection:1\n",
      "Parameters: number of layers:1, number of neurons in layers:[32], activation of layers:['relu']\n",
      "4/4 [==============================] - 0s 529us/step\n",
      "4/4 [==============================] - 0s 497us/step\n",
      "4/4 [==============================] - 0s 491us/step\n",
      "4/4 [==============================] - 0s 439us/step\n",
      "4/4 [==============================] - 0s 491us/step\n",
      "Average Cross-Validation Accuracy: 76.91%\n",
      "------------------------------\n",
      "[1, [32], ['relu']]\n",
      "0.7690909090909092\n",
      "5/5 [==============================] - 0s 426us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[128, 64, 32], activation of layers:['relu', 'relu', 'relu']\n",
      "4/4 [==============================] - 0s 515us/step\n",
      "4/4 [==============================] - 0s 493us/step\n",
      "4/4 [==============================] - 0s 496us/step\n",
      "4/4 [==============================] - 0s 548us/step\n",
      "4/4 [==============================] - 0s 524us/step\n",
      "Average Cross-Validation Accuracy: 90.55%\n",
      "------------------------------\n",
      "[3, [128, 64, 32], ['relu', 'relu', 'relu']]\n",
      "0.9054545454545455\n",
      "5/5 [==============================] - 0s 481us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[32, 16, 8], activation of layers:['relu', 'relu', 'sigmoid']\n",
      "4/4 [==============================] - 0s 547us/step\n",
      "4/4 [==============================] - 0s 501us/step\n",
      "4/4 [==============================] - 0s 514us/step\n",
      "4/4 [==============================] - 0s 505us/step\n",
      "4/4 [==============================] - 0s 519us/step\n",
      "Average Cross-Validation Accuracy: 79.64%\n",
      "------------------------------\n",
      "[3, [128, 64, 32], ['relu', 'relu', 'relu']]\n",
      "0.9054545454545455\n",
      "5/5 [==============================] - 0s 453us/step\n",
      "Number of Random Selection:2\n",
      "Parameters: number of layers:1, number of neurons in layers:[32], activation of layers:['relu']\n",
      "4/4 [==============================] - 0s 533us/step\n",
      "4/4 [==============================] - 0s 462us/step\n",
      "4/4 [==============================] - 0s 497us/step\n",
      "4/4 [==============================] - 0s 500us/step\n",
      "4/4 [==============================] - 0s 470us/step\n",
      "Average Cross-Validation Accuracy: 76.18%\n",
      "------------------------------\n",
      "[1, [32], ['relu']]\n",
      "0.761818181818182\n",
      "5/5 [==============================] - 0s 422us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[128, 64, 32], activation of layers:['relu', 'relu', 'relu']\n",
      "4/4 [==============================] - 0s 556us/step\n",
      "4/4 [==============================] - 0s 533us/step\n",
      "4/4 [==============================] - 0s 517us/step\n",
      "4/4 [==============================] - 0s 534us/step\n",
      "4/4 [==============================] - 0s 525us/step\n",
      "Average Cross-Validation Accuracy: 87.82%\n",
      "------------------------------\n",
      "[3, [128, 64, 32], ['relu', 'relu', 'relu']]\n",
      "0.8781818181818183\n",
      "5/5 [==============================] - 0s 448us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[32, 16, 8], activation of layers:['relu', 'relu', 'sigmoid']\n",
      "4/4 [==============================] - 0s 523us/step\n",
      "4/4 [==============================] - 0s 468us/step\n",
      "4/4 [==============================] - 0s 467us/step\n",
      "4/4 [==============================] - 0s 499us/step\n",
      "4/4 [==============================] - 0s 464us/step\n",
      "Average Cross-Validation Accuracy: 80.36%\n",
      "------------------------------\n",
      "[3, [128, 64, 32], ['relu', 'relu', 'relu']]\n",
      "0.8781818181818183\n",
      "5/5 [==============================] - 0s 437us/step\n",
      "Number of Random Selection:3\n",
      "Parameters: number of layers:1, number of neurons in layers:[32], activation of layers:['relu']\n",
      "4/4 [==============================] - 0s 509us/step\n",
      "4/4 [==============================] - 0s 487us/step\n",
      "4/4 [==============================] - 0s 454us/step\n",
      "4/4 [==============================] - 0s 488us/step\n",
      "4/4 [==============================] - 0s 513us/step\n",
      "Average Cross-Validation Accuracy: 73.82%\n",
      "------------------------------\n",
      "[1, [32], ['relu']]\n",
      "0.7381818181818182\n",
      "5/5 [==============================] - 0s 449us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[128, 64, 32], activation of layers:['relu', 'relu', 'relu']\n",
      "4/4 [==============================] - 0s 550us/step\n",
      "4/4 [==============================] - 0s 517us/step\n",
      "4/4 [==============================] - 0s 555us/step\n",
      "4/4 [==============================] - 0s 523us/step\n",
      "4/4 [==============================] - 0s 499us/step\n",
      "Average Cross-Validation Accuracy: 90.73%\n",
      "------------------------------\n",
      "[3, [128, 64, 32], ['relu', 'relu', 'relu']]\n",
      "0.9072727272727272\n",
      "5/5 [==============================] - 0s 490us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[32, 16, 8], activation of layers:['relu', 'relu', 'sigmoid']\n",
      "4/4 [==============================] - 0s 549us/step\n",
      "4/4 [==============================] - 0s 521us/step\n",
      "4/4 [==============================] - 0s 490us/step\n",
      "4/4 [==============================] - 0s 478us/step\n",
      "4/4 [==============================] - 0s 506us/step\n",
      "Average Cross-Validation Accuracy: 79.45%\n",
      "------------------------------\n",
      "[3, [128, 64, 32], ['relu', 'relu', 'relu']]\n",
      "0.9072727272727272\n",
      "5/5 [==============================] - 0s 450us/step\n"
     ]
    }
   ],
   "source": [
    "#print(type(fishersOfFeatures_freq[0]))\n",
    "import random\n",
    "\n",
    "number_of_features_all = 75\n",
    "number_of_features = 50\n",
    "num_it = 3\n",
    "sorted_Fisher_freq = sorted(fishersOfFeatures, key=lambda x: x[0], reverse=True)\n",
    "best_Fishers = sorted_Fisher_freq[:number_of_features_all]\n",
    "\n",
    "best_params_random = []\n",
    "best_acc_random = []\n",
    "\n",
    "#all_best_accuracies_MLP = []\n",
    "\n",
    "for i in range(num_it):\n",
    "    \n",
    "    print('Number of Random Selection:' + str(i+1))\n",
    "\n",
    "    best_Fishers_selected = random.sample(best_Fishers, number_of_features)\n",
    "\n",
    "    # all_random_selected_features_MLP.append(best_Fishers_selected)\n",
    "\n",
    "    best_features = []\n",
    "    best_features_test = []\n",
    "    best_features_names = []\n",
    "\n",
    "    for sublist in best_Fishers_selected:\n",
    "        best_features_names.append((sublist[1]))\n",
    "        best_features.append(sublist[2])\n",
    "        best_features_test.append(sublist[3])\n",
    "\n",
    "    best_features = np.array(best_features)\n",
    "    best_features_test = np.array(best_features_test)\n",
    "\n",
    "    # print(best_features.shape)\n",
    "    # print(best_features_test.shape)\n",
    "\n",
    "    # print(best_features_names)\n",
    "    # train_data: (500, 50), train_labels: (550, 1)\n",
    "    best_features = min_max_normalize(best_features)\n",
    "    best_features_test = min_max_normalize(best_features_test)\n",
    "\n",
    "    train_data = best_features_normalize.T\n",
    "    testing_data = best_features_test.T\n",
    "    train_labels = training_data_labels.T\n",
    "\n",
    "# Convert labels from -1 to 0 for compatibility with \"binary_crossentropy\" loss\n",
    "    train_labels = (train_labels + 1) / 2\n",
    "\n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "\n",
    "    parameters = [[1,[32],['relu']],\n",
    "              [3,[128,64,32],['relu','relu','relu']],\n",
    "              [3,[32,16,8],['relu','relu','sigmoid']],\n",
    "              ]\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_params = []\n",
    "\n",
    "    for params in parameters:\n",
    "        fold_accuracies = []\n",
    "        print(f'Parameters: number of layers:{params[0]}, number of neurons in layers:{params[1]}, activation of layers:{params[2]}')\n",
    "\n",
    "        model = create_mlp_model(params[0],params[1],params[2])\n",
    "        for train_index, val_index in kf.split(train_data):\n",
    "            X_train, X_val = train_data[train_index], train_data[val_index]\n",
    "            y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
    "\n",
    "            model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "            val_predictions = (model.predict(X_val) > 0.5).astype(int)\n",
    "            accuracy = accuracy_score(y_val, val_predictions)\n",
    "            fold_accuracies.append(accuracy)\n",
    "\n",
    "        average_accuracy = np.mean(fold_accuracies)\n",
    "        print(f'Average Cross-Validation Accuracy: {average_accuracy * 100:.2f}%')\n",
    "        print('-' * 30)\n",
    "\n",
    "        if average_accuracy > best_accuracy:\n",
    "            best_accuracy = average_accuracy\n",
    "            best_params = params\n",
    "        print(best_params)\n",
    "        print(best_accuracy)\n",
    "\n",
    "        model.fit(train_data, train_labels, epochs=30, batch_size=32, verbose=0)\n",
    "        test_predict = (model.predict(testing_data) > 0.5).astype(int)\n",
    "\n",
    "        all_predicted_MLP.append(test_predict)\n",
    "        all_best_accuracies_MLP.append(average_accuracy)\n",
    "\n",
    "    best_params_random.append(best_params)\n",
    "    best_acc_random.append(best_accuracy)\n",
    "\n",
    "    #all_best_accuracies_MLP.append(best_accuracy) \n",
    "    #all_random_selected_features_MLP.append(best_features)\n",
    "    \n",
    "\n",
    "    # print(all_best_params_MLP)  \n",
    "    # print(all_best_accuracies_MLP)    \n",
    "\n",
    "    # print(f'Best MLP Network Configuration:')\n",
    "    # print(f'Number of Layers: {best_params[0]}')\n",
    "    # print(f'Neurons per Layer: {best_params[1]}')\n",
    "    # print(f'Activation Function: {best_params[2]}')\n",
    "    # print(f'Average Cross-Validation Accuracy: {best_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of random selstion:0, Number of Layers: 3, Neurons per Layer: [128, 64, 32], Activation Function: ['relu', 'relu', 'relu'], Average Cross-Validation Accuracy: 90.55\n",
      "Num of random selstion:1, Number of Layers: 3, Neurons per Layer: [128, 64, 32], Activation Function: ['relu', 'relu', 'relu'], Average Cross-Validation Accuracy: 87.82\n",
      "Num of random selstion:2, Number of Layers: 3, Neurons per Layer: [128, 64, 32], Activation Function: ['relu', 'relu', 'relu'], Average Cross-Validation Accuracy: 90.73\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_it):\n",
    "    p = best_params_random[i]\n",
    "    print(f'Num of random selstion:{i}, Number of Layers: {p[0]}, Neurons per Layer: {p[1]}, Activation Function: {p[2]}, Average Cross-Validation Accuracy: {best_acc_random[i] * 100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicted values using MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "[1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0\n",
      " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 0 1 1\n",
      " 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1\n",
      " 1 1 1 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(all_best_accuracies_MLP))\n",
    "print(len(all_predicted_MLP))\n",
    "max_acc = np.argmax(all_best_accuracies_MLP)\n",
    "predicted_MLP_Fisher = all_predicted_MLP[max_acc]\n",
    "predicted_MLP_Fisher = predicted_MLP_Fisher.ravel()\n",
    "print(predicted_MLP_Fisher)\n",
    "# p_best_MLP = all_best_params_MLP[max_acc]\n",
    "# print(p_best_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *RBF*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best 50 features using Fisher method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 550)\n",
      "(50, 159)\n"
     ]
    }
   ],
   "source": [
    "#print(type(fishersOfFeatures_freq[0]))\n",
    "number_of_features = 50\n",
    "\n",
    "sorted_Fisher_freq = sorted(fishersOfFeatures, key=lambda x: x[0], reverse=True)\n",
    "best_Fishers = sorted_Fisher_freq[:number_of_features]\n",
    "\n",
    "best_features = []\n",
    "best_features_test = []\n",
    "best_features_names = []\n",
    "\n",
    "for sublist in best_Fishers:\n",
    "    best_features_names.append((sublist[1]))\n",
    "    best_features.append(sublist[2])\n",
    "    best_features_test.append(sublist[3])\n",
    "\n",
    "best_features = np.array(best_features)\n",
    "\n",
    "best_features_test = np.array(best_features_test)\n",
    "\n",
    "\n",
    "print(best_features.shape)\n",
    "print(best_features_test.shape)\n",
    "\n",
    "#print(best_features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 550)\n"
     ]
    }
   ],
   "source": [
    "best_features_normalize = min_max_normalize(best_features)\n",
    "best_features_test_normalize = min_max_normalize(best_features_test)\n",
    "print(best_features_normalize.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_best_accuracies_RBF = []\n",
    "all_predicted_RBF = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implement RBF network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 50)\n",
      "Accuracies for Different Parameter Combinations:\n",
      "Parameters: {'C': 0.1, 'gamma': 1} - Accuracy: 60.18\n",
      "Parameters: {'C': 0.1, 'gamma': 0.1} - Accuracy: 64.00\n",
      "Parameters: {'C': 0.1, 'gamma': 0.01} - Accuracy: 50.36\n",
      "Parameters: {'C': 0.1, 'gamma': 0.001} - Accuracy: 50.36\n",
      "Parameters: {'C': 1, 'gamma': 1} - Accuracy: 78.73\n",
      "Parameters: {'C': 1, 'gamma': 0.1} - Accuracy: 68.91\n",
      "Parameters: {'C': 1, 'gamma': 0.01} - Accuracy: 64.73\n",
      "Parameters: {'C': 1, 'gamma': 0.001} - Accuracy: 50.36\n",
      "Parameters: {'C': 10, 'gamma': 1} - Accuracy: 81.64\n",
      "Parameters: {'C': 10, 'gamma': 0.1} - Accuracy: 74.55\n",
      "Parameters: {'C': 10, 'gamma': 0.01} - Accuracy: 68.36\n",
      "Parameters: {'C': 10, 'gamma': 0.001} - Accuracy: 65.27\n",
      "Parameters: {'C': 15, 'gamma': 1} - Accuracy: 80.73\n",
      "Parameters: {'C': 15, 'gamma': 0.1} - Accuracy: 74.36\n",
      "Parameters: {'C': 15, 'gamma': 0.01} - Accuracy: 69.64\n",
      "Parameters: {'C': 15, 'gamma': 0.001} - Accuracy: 65.64\n",
      "Parameters: {'C': 18, 'gamma': 1} - Accuracy: 80.55\n",
      "Parameters: {'C': 18, 'gamma': 0.1} - Accuracy: 75.09\n",
      "Parameters: {'C': 18, 'gamma': 0.01} - Accuracy: 69.82\n",
      "Parameters: {'C': 18, 'gamma': 0.001} - Accuracy: 65.45\n",
      "Parameters: {'C': 100, 'gamma': 1} - Accuracy: 80.55\n",
      "Parameters: {'C': 100, 'gamma': 0.1} - Accuracy: 78.55\n",
      "Parameters: {'C': 100, 'gamma': 0.01} - Accuracy: 72.36\n",
      "Parameters: {'C': 100, 'gamma': 0.001} - Accuracy: 68.55\n",
      "------------------------------\n",
      "\n",
      "Best Parameters: {'C': 10, 'gamma': 1}\n",
      "Average Cross-Validation Accuracy: 81.64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "train_data = best_features_normalize.T\n",
    "train_labels = training_data_labels.T\n",
    "tesing_data1 = best_features_test_normalize.T\n",
    "print(tesing_data1.shape)\n",
    "\n",
    "# Convert labels from -1 to 0 for compatibility with \"binary_crossentropy\" loss\n",
    "train_labels = (train_labels + 1) / 2\n",
    "\n",
    "train_labels = train_labels.flatten()\n",
    "\n",
    "\n",
    "svm_model = SVC(kernel='rbf')\n",
    "\n",
    "# Define the parameters\n",
    "Cs = [0.1, 1, 10, 15, 18, 100]\n",
    "gammas = [1, 0.1, 0.01, 0.001]\n",
    "\n",
    "best_params = {'C': None, 'gamma': None}\n",
    "best_accuracy = 0.0\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "print(\"Accuracies for Different Parameter Combinations:\")\n",
    "for C in Cs:\n",
    "    for gamma in gammas:\n",
    "\n",
    "        current_model = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "        cv_scores = cross_val_score(current_model, train_data, train_labels, cv=5, scoring='accuracy')\n",
    "        average_accuracy = np.mean(cv_scores)\n",
    "\n",
    "        current_model.fit(train_data, train_labels)\n",
    "        test_prediction = current_model.predict(tesing_data1)\n",
    "        #print(test_prediction.shape)\n",
    "\n",
    "        all_best_accuracies_RBF.append(average_accuracy)\n",
    "        all_predicted_RBF.append(test_prediction)\n",
    "\n",
    "        print(f\"Parameters: {{'C': {C}, 'gamma': {gamma}}} - Accuracy: {average_accuracy* 100:.2f}\")\n",
    "\n",
    "        if average_accuracy > best_accuracy:\n",
    "            best_accuracy = average_accuracy\n",
    "            best_params['C'] = C\n",
    "            best_params['gamma'] = gamma\n",
    "\n",
    "print('-' * 30)\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f'Average Cross-Validation Accuracy: {best_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(all_best_accuracies_RBF))\n",
    "print(len(all_predicted_RBF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomly selecting 50 of 75 best features (according to Fisher method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Random Selection:1\n",
      "Accuracies for Different Parameter Combinations:\n",
      "Parameters: {'C': 0.1, 'gamma': 1} - Accuracy: 57.27\n",
      "Parameters: {'C': 0.1, 'gamma': 0.1} - Accuracy: 61.82\n",
      "Parameters: {'C': 0.1, 'gamma': 0.01} - Accuracy: 50.36\n",
      "Parameters: {'C': 0.1, 'gamma': 0.001} - Accuracy: 50.36\n",
      "Parameters: {'C': 1, 'gamma': 1} - Accuracy: 78.91\n",
      "Parameters: {'C': 1, 'gamma': 0.1} - Accuracy: 69.64\n",
      "Parameters: {'C': 1, 'gamma': 0.01} - Accuracy: 62.73\n",
      "Parameters: {'C': 1, 'gamma': 0.001} - Accuracy: 50.36\n",
      "Parameters: {'C': 10, 'gamma': 1} - Accuracy: 82.00\n",
      "Parameters: {'C': 10, 'gamma': 0.1} - Accuracy: 74.55\n",
      "Parameters: {'C': 10, 'gamma': 0.01} - Accuracy: 68.55\n",
      "Parameters: {'C': 10, 'gamma': 0.001} - Accuracy: 63.45\n",
      "Parameters: {'C': 15, 'gamma': 1} - Accuracy: 82.00\n",
      "Parameters: {'C': 15, 'gamma': 0.1} - Accuracy: 74.91\n",
      "Parameters: {'C': 15, 'gamma': 0.01} - Accuracy: 70.18\n",
      "Parameters: {'C': 15, 'gamma': 0.001} - Accuracy: 63.45\n",
      "Parameters: {'C': 18, 'gamma': 1} - Accuracy: 82.00\n",
      "Parameters: {'C': 18, 'gamma': 0.1} - Accuracy: 77.09\n",
      "Parameters: {'C': 18, 'gamma': 0.01} - Accuracy: 70.91\n",
      "Parameters: {'C': 18, 'gamma': 0.001} - Accuracy: 63.64\n",
      "Parameters: {'C': 100, 'gamma': 1} - Accuracy: 82.00\n",
      "Parameters: {'C': 100, 'gamma': 0.1} - Accuracy: 78.18\n",
      "Parameters: {'C': 100, 'gamma': 0.01} - Accuracy: 74.18\n",
      "Parameters: {'C': 100, 'gamma': 0.001} - Accuracy: 68.36\n",
      "\n",
      "Best Parameters: [10, 1]\n",
      "Average Cross-Validation Accuracy: 82.00%\n",
      "Number of Random Selection:2\n",
      "Accuracies for Different Parameter Combinations:\n",
      "Parameters: {'C': 0.1, 'gamma': 1} - Accuracy: 58.00\n",
      "Parameters: {'C': 0.1, 'gamma': 0.1} - Accuracy: 64.36\n",
      "Parameters: {'C': 0.1, 'gamma': 0.01} - Accuracy: 50.36\n",
      "Parameters: {'C': 0.1, 'gamma': 0.001} - Accuracy: 50.36\n",
      "Parameters: {'C': 1, 'gamma': 1} - Accuracy: 79.45\n",
      "Parameters: {'C': 1, 'gamma': 0.1} - Accuracy: 69.82\n",
      "Parameters: {'C': 1, 'gamma': 0.01} - Accuracy: 64.91\n",
      "Parameters: {'C': 1, 'gamma': 0.001} - Accuracy: 50.36\n",
      "Parameters: {'C': 10, 'gamma': 1} - Accuracy: 81.27\n",
      "Parameters: {'C': 10, 'gamma': 0.1} - Accuracy: 75.45\n",
      "Parameters: {'C': 10, 'gamma': 0.01} - Accuracy: 70.36\n",
      "Parameters: {'C': 10, 'gamma': 0.001} - Accuracy: 64.91\n",
      "Parameters: {'C': 15, 'gamma': 1} - Accuracy: 81.27\n",
      "Parameters: {'C': 15, 'gamma': 0.1} - Accuracy: 75.09\n",
      "Parameters: {'C': 15, 'gamma': 0.01} - Accuracy: 72.18\n",
      "Parameters: {'C': 15, 'gamma': 0.001} - Accuracy: 64.55\n",
      "Parameters: {'C': 18, 'gamma': 1} - Accuracy: 81.27\n",
      "Parameters: {'C': 18, 'gamma': 0.1} - Accuracy: 74.73\n",
      "Parameters: {'C': 18, 'gamma': 0.01} - Accuracy: 72.18\n",
      "Parameters: {'C': 18, 'gamma': 0.001} - Accuracy: 64.36\n",
      "Parameters: {'C': 100, 'gamma': 1} - Accuracy: 81.27\n",
      "Parameters: {'C': 100, 'gamma': 0.1} - Accuracy: 78.18\n",
      "Parameters: {'C': 100, 'gamma': 0.01} - Accuracy: 74.18\n",
      "Parameters: {'C': 100, 'gamma': 0.001} - Accuracy: 70.18\n",
      "\n",
      "Best Parameters: [10, 1]\n",
      "Average Cross-Validation Accuracy: 81.27%\n",
      "Number of Random Selection:3\n",
      "Accuracies for Different Parameter Combinations:\n",
      "Parameters: {'C': 0.1, 'gamma': 1} - Accuracy: 55.27\n",
      "Parameters: {'C': 0.1, 'gamma': 0.1} - Accuracy: 62.55\n",
      "Parameters: {'C': 0.1, 'gamma': 0.01} - Accuracy: 50.36\n",
      "Parameters: {'C': 0.1, 'gamma': 0.001} - Accuracy: 50.36\n",
      "Parameters: {'C': 1, 'gamma': 1} - Accuracy: 79.27\n",
      "Parameters: {'C': 1, 'gamma': 0.1} - Accuracy: 68.00\n",
      "Parameters: {'C': 1, 'gamma': 0.01} - Accuracy: 63.64\n",
      "Parameters: {'C': 1, 'gamma': 0.001} - Accuracy: 50.36\n",
      "Parameters: {'C': 10, 'gamma': 1} - Accuracy: 82.00\n",
      "Parameters: {'C': 10, 'gamma': 0.1} - Accuracy: 72.73\n",
      "Parameters: {'C': 10, 'gamma': 0.01} - Accuracy: 66.55\n",
      "Parameters: {'C': 10, 'gamma': 0.001} - Accuracy: 64.18\n",
      "Parameters: {'C': 15, 'gamma': 1} - Accuracy: 82.18\n",
      "Parameters: {'C': 15, 'gamma': 0.1} - Accuracy: 74.36\n",
      "Parameters: {'C': 15, 'gamma': 0.01} - Accuracy: 67.82\n",
      "Parameters: {'C': 15, 'gamma': 0.001} - Accuracy: 64.55\n",
      "Parameters: {'C': 18, 'gamma': 1} - Accuracy: 82.18\n",
      "Parameters: {'C': 18, 'gamma': 0.1} - Accuracy: 74.18\n",
      "Parameters: {'C': 18, 'gamma': 0.01} - Accuracy: 67.64\n",
      "Parameters: {'C': 18, 'gamma': 0.001} - Accuracy: 64.00\n",
      "Parameters: {'C': 100, 'gamma': 1} - Accuracy: 82.18\n",
      "Parameters: {'C': 100, 'gamma': 0.1} - Accuracy: 76.91\n",
      "Parameters: {'C': 100, 'gamma': 0.01} - Accuracy: 69.82\n",
      "Parameters: {'C': 100, 'gamma': 0.001} - Accuracy: 67.09\n",
      "\n",
      "Best Parameters: [15, 1]\n",
      "Average Cross-Validation Accuracy: 82.18%\n",
      "Number of Random Selection:4\n",
      "Accuracies for Different Parameter Combinations:\n",
      "Parameters: {'C': 0.1, 'gamma': 1} - Accuracy: 57.09\n",
      "Parameters: {'C': 0.1, 'gamma': 0.1} - Accuracy: 62.55\n",
      "Parameters: {'C': 0.1, 'gamma': 0.01} - Accuracy: 50.36\n",
      "Parameters: {'C': 0.1, 'gamma': 0.001} - Accuracy: 50.36\n",
      "Parameters: {'C': 1, 'gamma': 1} - Accuracy: 80.18\n",
      "Parameters: {'C': 1, 'gamma': 0.1} - Accuracy: 68.91\n",
      "Parameters: {'C': 1, 'gamma': 0.01} - Accuracy: 63.82\n",
      "Parameters: {'C': 1, 'gamma': 0.001} - Accuracy: 50.36\n",
      "Parameters: {'C': 10, 'gamma': 1} - Accuracy: 83.09\n",
      "Parameters: {'C': 10, 'gamma': 0.1} - Accuracy: 75.64\n",
      "Parameters: {'C': 10, 'gamma': 0.01} - Accuracy: 68.55\n",
      "Parameters: {'C': 10, 'gamma': 0.001} - Accuracy: 63.82\n",
      "Parameters: {'C': 15, 'gamma': 1} - Accuracy: 83.09\n",
      "Parameters: {'C': 15, 'gamma': 0.1} - Accuracy: 76.73\n",
      "Parameters: {'C': 15, 'gamma': 0.01} - Accuracy: 69.45\n",
      "Parameters: {'C': 15, 'gamma': 0.001} - Accuracy: 63.82\n",
      "Parameters: {'C': 18, 'gamma': 1} - Accuracy: 83.09\n",
      "Parameters: {'C': 18, 'gamma': 0.1} - Accuracy: 77.64\n",
      "Parameters: {'C': 18, 'gamma': 0.01} - Accuracy: 68.91\n",
      "Parameters: {'C': 18, 'gamma': 0.001} - Accuracy: 64.36\n",
      "Parameters: {'C': 100, 'gamma': 1} - Accuracy: 83.09\n",
      "Parameters: {'C': 100, 'gamma': 0.1} - Accuracy: 80.36\n",
      "Parameters: {'C': 100, 'gamma': 0.01} - Accuracy: 72.55\n",
      "Parameters: {'C': 100, 'gamma': 0.001} - Accuracy: 68.18\n",
      "\n",
      "Best Parameters: [10, 1]\n",
      "Average Cross-Validation Accuracy: 83.09%\n"
     ]
    }
   ],
   "source": [
    "#print(type(fishersOfFeatures_freq[0]))\n",
    "import random\n",
    "\n",
    "number_of_features_all = 75\n",
    "number_of_features = 50\n",
    "num_it = 4\n",
    "sorted_Fisher_freq = sorted(fishersOfFeatures, key=lambda x: x[0], reverse=True)\n",
    "best_Fishers = sorted_Fisher_freq[:number_of_features_all]\n",
    "\n",
    "\n",
    "best_params_RBF = []\n",
    "best_accuracies_RBF = []\n",
    "#all_random_selected_features_RBF = []\n",
    "for i in range(num_it):\n",
    "    \n",
    "    print('Number of Random Selection:' + str(i+1))\n",
    "\n",
    "    random_Fishers_selected = random.sample(best_Fishers, number_of_features)\n",
    "    #all_random_selected_features_RBF.append(best_Fishers_selected)\n",
    "\n",
    "\n",
    "    best_features = []\n",
    "    best_features_test = []\n",
    "    best_features_names = []\n",
    "\n",
    "    for sublist in random_Fishers_selected:\n",
    "        best_features_names.append((sublist[1]))\n",
    "        best_features.append(sublist[2])\n",
    "        best_features_test.append(sublist[3])\n",
    "\n",
    "\n",
    "    best_features = np.array(best_features)\n",
    "    best_features_test = np.array(best_features_test)\n",
    "\n",
    "    best_features = min_max_normalize(best_features)\n",
    "    best_features_test = min_max_normalize(best_features_test)\n",
    "\n",
    "    train_data = best_features.T\n",
    "    testing_data = best_features_test.T\n",
    "    train_labels = training_data_labels.T\n",
    "\n",
    "    # Convert labels from -1 to 0 for compatibility with \"binary_crossentropy\" loss\n",
    "    train_labels = (train_labels + 1) / 2\n",
    "    train_labels = train_labels.flatten()\n",
    "\n",
    "    svm_model = SVC(kernel='rbf')\n",
    "\n",
    "    # Define the parameters\n",
    "    Cs = [0.1, 1, 10, 15, 18, 100]\n",
    "    gammas = [1, 0.1, 0.01, 0.001]\n",
    "\n",
    "    best_params = []\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "\n",
    "    print(\"Accuracies for Different Parameter Combinations:\")\n",
    "    for C in Cs:\n",
    "        for gamma in gammas:\n",
    "\n",
    "            current_model = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "            cv_scores = cross_val_score(current_model, train_data, train_labels, cv=5, scoring='accuracy')\n",
    "            average_accuracy = np.mean(cv_scores)\n",
    "\n",
    "            current_model.fit(train_data, train_labels)\n",
    "            test_prediction = current_model.predict(testing_data)\n",
    "            #print(test_prediction.shape)\n",
    "\n",
    "            all_best_accuracies_RBF.append(average_accuracy)\n",
    "            all_predicted_RBF.append(test_prediction)\n",
    "\n",
    "            print(f\"Parameters: {{'C': {C}, 'gamma': {gamma}}} - Accuracy: {average_accuracy* 100:.2f}\")\n",
    "\n",
    "            if average_accuracy > best_accuracy:\n",
    "                best_accuracy = average_accuracy\n",
    "                best_params = [C,gamma]\n",
    "                #best_params['gamma'] = gamma\n",
    "\n",
    "  \n",
    "            # print(best_params)\n",
    "            # print(best_accuracy)\n",
    "    #print('-' * 30)\n",
    "    print(\"\\nBest Parameters:\", best_params)\n",
    "    print(f'Average Cross-Validation Accuracy: {best_accuracy * 100:.2f}%')\n",
    "\n",
    "    best_params_RBF.append(best_params) \n",
    "    best_accuracies_RBF.append(best_accuracy) \n",
    "    # print(all_best_params_RBF)  \n",
    "    # print(all_best_accuracies_RBF)    \n",
    "\n",
    "    # print(f'Best MLP Network Configuration:')\n",
    "    # print(f'Number of Layers: {best_params[0]}')\n",
    "    # print(f'Neurons per Layer: {best_params[1]}')\n",
    "    # print(f'Activation Function: {best_params[2]}')\n",
    "    # print(f'Average Cross-Validation Accuracy: {best_accuracy * 100:.2f}%')\n",
    "\n",
    "# print(len(all_best_params_RBF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of random selction:0, C: 10, gamma: 1, Average Cross-Validation Accuracy: 82.00\n",
      "Num of random selction:1, C: 10, gamma: 1, Average Cross-Validation Accuracy: 81.27\n",
      "Num of random selction:2, C: 15, gamma: 1, Average Cross-Validation Accuracy: 82.18\n",
      "Num of random selction:3, C: 10, gamma: 1, Average Cross-Validation Accuracy: 83.09\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_it):\n",
    "    p = best_params_RBF[i]\n",
    "    print(f'Num of random selction:{i}, C: {p[0]}, gamma: {p[1]}, Average Cross-Validation Accuracy: {best_accuracies_RBF[i] * 100:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicted values using RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(len(all_best_accuracies_RBF))\n",
    "print(len(all_predicted_RBF))\n",
    "max_acc = np.argmax(all_best_accuracies_RBF)\n",
    "predicted_RBF_Fisher = all_predicted_RBF[max_acc]\n",
    "print(predicted_RBF_Fisher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 best features according to Fisher method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 550)\n",
      "(1000, 550)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#print(type(fishersOfFeatures_freq[0]))\n",
    "number_of_features_g = 1000\n",
    "\n",
    "sorted_Fisher_freq_g  = sorted(fishersOfFeatures, key=lambda x: x[0], reverse=True)\n",
    "best_Fishers_g  = sorted_Fisher_freq_g [:number_of_features_g]\n",
    "\n",
    "best_features_g  = []\n",
    "best_features_test_g  = []\n",
    "best_features_names_g = []\n",
    "\n",
    "for sublist in best_Fishers_g:\n",
    "    best_features_names_g.append((sublist[1]))\n",
    "    best_features_g.append(sublist[2])\n",
    "    best_features_test_g.append(sublist[3])\n",
    "\n",
    "best_features_g  = np.array(best_features_g )\n",
    "best_features_test_g  = np.array(best_features_test_g)\n",
    "best_features_g_normalize = min_max_normalize(best_features_g)\n",
    "best_features_test_g_normalize = min_max_normalize(best_features_test_g)\n",
    "\n",
    "print(best_features_g_normalize.shape)\n",
    "print(best_features_g_normalize.shape)\n",
    "print(type(best_features_g))\n",
    "\n",
    "#print(best_features_names_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 1000)\n",
      "(550, 1)\n"
     ]
    }
   ],
   "source": [
    "X = best_features_g_normalize.T\n",
    "y = training_data_labels.T\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: [0, 2, 3, 5, 6, 9, 16, 17, 20, 23, 24, 27, 28, 29, 32, 38, 40, 42, 46, 48, 50, 51, 52, 54, 56, 57, 58, 59, 62, 63, 64, 65, 70, 72, 73, 75, 79, 80, 81, 83, 84, 88, 90, 91, 94, 96, 97, 98, 99, 100, 102, 104, 107, 109, 110, 115, 117, 119, 122, 126, 127, 130, 132, 136, 138, 139, 142, 151, 152, 156, 157, 159, 160, 163, 168, 170, 171, 172, 173, 178, 180, 181, 182, 184, 189, 190, 191, 195, 198, 200, 208, 209, 210, 211, 214, 216, 217, 222, 224, 225, 226, 227, 229, 230, 231, 232, 235, 236, 238, 239, 240, 244, 245, 247, 256, 259, 260, 261, 264, 265, 270, 271, 273, 274, 275, 277, 279, 282, 283, 287, 289, 293, 298, 299, 301, 302, 303, 304, 306, 316, 317, 318, 319, 320, 321, 323, 325, 326, 327, 328, 329, 330, 331, 333, 334, 337, 339, 344, 345, 347, 348, 350, 352, 353, 354, 358, 361, 366, 370, 373, 375, 376, 378, 380, 383, 385, 388, 393, 394, 395, 396, 399, 400, 401, 404, 405, 409, 410, 411, 414, 418, 419, 421, 428, 429, 431, 433, 436, 438, 442, 447, 448, 450, 451, 452, 453, 455, 463, 465, 466, 468, 470, 473, 475, 477, 478, 480, 481, 482, 483, 485, 486, 489, 492, 493, 494, 496, 497, 498, 500, 501, 502, 504, 507, 511, 514, 515, 520, 522, 523, 525, 527, 528, 531, 533, 534, 538, 539, 540, 543, 544, 549, 551, 553, 555, 557, 558, 560, 561, 565, 566, 567, 568, 571, 572, 573, 574, 576, 578, 579, 580, 581, 583, 584, 586, 589, 591, 596, 597, 598, 600, 603, 604, 610, 611, 613, 614, 621, 623, 626, 631, 632, 634, 635, 637, 638, 639, 640, 641, 643, 645, 656, 657, 659, 664, 666, 670, 671, 674, 675, 677, 685, 686, 688, 690, 693, 694, 695, 698, 699, 704, 705, 708, 709, 710, 712, 714, 718, 720, 721, 726, 733, 736, 740, 741, 746, 747, 751, 752, 753, 755, 757, 762, 767, 769, 774, 779, 780, 781, 783, 784, 785, 786, 787, 790, 791, 793, 796, 799, 801, 804, 805, 806, 809, 810, 817, 818, 820, 827, 830, 833, 834, 835, 836, 844, 845, 847, 848, 852, 853, 856, 861, 863, 864, 865, 868, 869, 874, 879, 882, 883, 884, 888, 891, 895, 897, 899, 900, 903, 906, 907, 908, 910, 912, 913, 915, 917, 918, 919, 920, 921, 922, 924, 925, 927, 929, 931, 932, 933, 937, 942, 943, 944, 945, 946, 947, 949, 951, 952, 957, 961, 965, 966, 967, 968, 969, 972, 973, 976, 979, 984, 986, 989, 990, 992, 993, 996]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, num_features):\n",
    "        self.position = np.random.choice([0.0, 1.0], size=num_features)\n",
    "        self.velocity = np.random.rand(num_features) * 0.15\n",
    "        self.best_position = self.position.copy()\n",
    "        self.best_score = float('inf')\n",
    "\n",
    "\n",
    "def update_velocity(particle, top_position, w=0.05, a=0.01, b=0.01):\n",
    "    r1, r2 = np.random.rand(2, particle.velocity.shape[0])\n",
    "    self_velocity = a * r1 * (particle.best_position.astype(np.float32) - particle.position.astype(np.float32))\n",
    "    neighbor_velocity = b * r2 * (top_position.astype(np.float32) - particle.position.astype(np.float32))\n",
    "    particle.velocity = w * particle.velocity + self_velocity + neighbor_velocity\n",
    "\n",
    "def update_position(particle):\n",
    "    prob = 1 / (1 + np.exp(-particle.velocity))\n",
    "    particle.position = np.random.rand(len(particle.position)) < prob\n",
    "\n",
    "def fitness_function(selected_features, X_subset, y):\n",
    "    num_features_selected = len(selected_features)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=20)\n",
    "    scores = cross_val_score(clf, X_subset, y, cv=5)\n",
    "    \n",
    "    penalty = 0\n",
    "    ideal_feature_count = 100\n",
    "    if num_features_selected > ideal_feature_count:\n",
    "        penalty = abs(num_features_selected - ideal_feature_count) * 500\n",
    "    \n",
    "    if num_features_selected == 0:\n",
    "        return float('inf')\n",
    "\n",
    "    return -(scores.mean()) + penalty\n",
    "\n",
    "\n",
    "\n",
    "def pso(X_subset, y, num_features, num_particles=30, iter=50):\n",
    "    particles = [Particle(num_features) for _ in range(num_particles)]\n",
    "    top_score = float('inf')\n",
    "    top_position = np.zeros(num_features)\n",
    "\n",
    "    for t in range(iter):\n",
    "        for particle in particles:\n",
    "            evaluation = fitness_function(\n",
    "                [i for i, bit in enumerate(particle.position) if bit],\n",
    "                X_subset,\n",
    "                y\n",
    "            )\n",
    "\n",
    "            if evaluation < top_score:\n",
    "                top_score = evaluation\n",
    "                top_position = particle.position.copy()\n",
    "\n",
    "            if evaluation < particle.best_score:\n",
    "                particle.best_score = evaluation\n",
    "                particle.best_position = particle.position.copy()\n",
    "\n",
    "        for particle in particles:\n",
    "            update_velocity(particle, top_position)\n",
    "            update_position(particle)\n",
    "\n",
    "    return top_position, top_score\n",
    "\n",
    "# Run PSO\n",
    "selected_position, _ = pso(X, y.ravel(), number_of_features_g)\n",
    "selected_features_pso = [i for i, bit in enumerate(selected_position > 0.5) if bit]\n",
    "\n",
    "print(\"Selected features:\", selected_features_pso)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 1000)\n",
      "X_train shape: (550, 447)\n",
      "(159, 447)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X_train_PSO = X[:, selected_features_pso]\n",
    "print(\"X_train shape:\", X_train_PSO.shape)\n",
    "X_test = best_features_test_g_normalize.T[:, selected_features_pso]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_best_accuracies_MLP_PSO = []\n",
    "all_predicted_MLP_PSO = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 447)\n",
      "(550, 447)\n",
      "(550, 1)\n",
      "(159, 447)\n",
      "Parameters: number of layers:1, number of neurons in layers:[32], activation of layers:['relu']\n",
      "4/4 [==============================] - 0s 617us/step\n",
      "4/4 [==============================] - 0s 480us/step\n",
      "4/4 [==============================] - 0s 527us/step\n",
      "4/4 [==============================] - 0s 479us/step\n",
      "4/4 [==============================] - 0s 497us/step\n",
      "Average Cross-Validation Accuracy: 90.00%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 451us/step\n",
      "Parameters: number of layers:2, number of neurons in layers:[64, 32], activation of layers:['relu', 'relu']\n",
      "4/4 [==============================] - 0s 528us/step\n",
      "4/4 [==============================] - 0s 472us/step\n",
      "4/4 [==============================] - 0s 516us/step\n",
      "4/4 [==============================] - 0s 495us/step\n",
      "4/4 [==============================] - 0s 475us/step\n",
      "Average Cross-Validation Accuracy: 93.45%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 472us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[128, 64, 32], activation of layers:['relu', 'relu', 'sigmoid']\n",
      "4/4 [==============================] - 0s 559us/step\n",
      "4/4 [==============================] - 0s 548us/step\n",
      "4/4 [==============================] - 0s 551us/step\n",
      "4/4 [==============================] - 0s 525us/step\n",
      "4/4 [==============================] - 0s 532us/step\n",
      "Average Cross-Validation Accuracy: 96.18%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 500us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[128, 64, 32], activation of layers:['relu', 'relu', 'relu']\n",
      "4/4 [==============================] - 0s 571us/step\n",
      "4/4 [==============================] - 0s 552us/step\n",
      "4/4 [==============================] - 0s 514us/step\n",
      "4/4 [==============================] - 0s 560us/step\n",
      "4/4 [==============================] - 0s 544us/step\n",
      "Average Cross-Validation Accuracy: 95.27%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 528us/step\n",
      "Parameters: number of layers:3, number of neurons in layers:[32, 16, 8], activation of layers:['relu', 'relu', 'sigmoid']\n",
      "4/4 [==============================] - 0s 541us/step\n",
      "4/4 [==============================] - 0s 549us/step\n",
      "4/4 [==============================] - 0s 500us/step\n",
      "4/4 [==============================] - 0s 521us/step\n",
      "4/4 [==============================] - 0s 575us/step\n",
      "Average Cross-Validation Accuracy: 92.73%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 593us/step\n",
      "Parameters: number of layers:4, number of neurons in layers:[128, 63, 32, 16], activation of layers:['relu', 'relu', 'relu', 'relu']\n",
      "4/4 [==============================] - 0s 678us/step\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "4/4 [==============================] - 0s 651us/step\n",
      "4/4 [==============================] - 0s 609us/step\n",
      "4/4 [==============================] - 0s 641us/step\n",
      "Average Cross-Validation Accuracy: 96.36%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 525us/step\n",
      "Parameters: number of layers:5, number of neurons in layers:[32, 64, 128, 64, 32], activation of layers:['relu', 'relu', 'relu', 'relu', 'relu']\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "4/4 [==============================] - 0s 739us/step\n",
      "4/4 [==============================] - 0s 579us/step\n",
      "4/4 [==============================] - 0s 526us/step\n",
      "4/4 [==============================] - 0s 578us/step\n",
      "Average Cross-Validation Accuracy: 95.82%\n",
      "------------------------------\n",
      "5/5 [==============================] - 0s 507us/step\n"
     ]
    }
   ],
   "source": [
    "print(X_train_PSO.shape)\n",
    "train_data = X_train_PSO\n",
    "train_labels = training_data_labels.T\n",
    "testing_data = X_test\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(testing_data.shape)\n",
    "\n",
    "# Convert labels from -1 to 0 for compatibility with \"binary_crossentropy\" loss\n",
    "train_labels = (train_labels + 1) / 2\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "parameters = [[1,[32],['relu']],\n",
    "              [2,[64,32],['relu','relu']],\n",
    "              [3,[128,64,32],['relu','relu','sigmoid']],\n",
    "              [3,[128,64,32],['relu','relu','relu']],\n",
    "              [3,[32,16,8],['relu','relu','sigmoid']],\n",
    "              [4,[128,63,32,16],['relu','relu','relu','relu']],\n",
    "              [5,[32,64,128,64,32],['relu','relu','relu','relu','relu']]\n",
    "              ]\n",
    "\n",
    "def create_mlp_model(num_layers, neurons_per_layer, activation):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=neurons_per_layer[0], activation=activation[0], input_dim=train_data.shape[1]))\n",
    "\n",
    "    for i in range(1, num_layers - 1):\n",
    "        model.add(Dense(units=neurons_per_layer[i], activation=activation[i]))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for params in parameters:\n",
    "    fold_accuracies = []\n",
    "    model = create_mlp_model(params[0],params[1],params[2])\n",
    "    print(f'Parameters: number of layers:{params[0]}, number of neurons in layers:{params[1]}, activation of layers:{params[2]}')\n",
    "    for train_index, val_index in kf.split(train_data):\n",
    "        X_train, X_val = train_data[train_index], train_data[val_index]\n",
    "        y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
    "\n",
    "        \n",
    "        model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "        val_predictions = (model.predict(X_val) > 0.5).astype(int)\n",
    "        accuracy = accuracy_score(y_val, val_predictions)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "    average_accuracy = np.mean(fold_accuracies)\n",
    "    print(f'Average Cross-Validation Accuracy: {average_accuracy * 100:.2f}%')\n",
    "    print('-' * 30)\n",
    "\n",
    "\n",
    "    model.fit(train_data, train_labels, epochs=30, batch_size=32, verbose=0)\n",
    "\n",
    "    test_predict = (model.predict(testing_data) > 0.5).astype(int)\n",
    "\n",
    "    #all_best_params_MLP.append(params)\n",
    "    all_best_accuracies_MLP_PSO.append(average_accuracy)\n",
    "    all_predicted_MLP_PSO.append(test_predict)\n",
    "\n",
    "    if average_accuracy > best_accuracy:\n",
    "        best_accuracy = average_accuracy\n",
    "        best_params = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP Network Configuration:\n",
      "Number of Layers: 4\n",
      "Neurons per Layer: [128, 63, 32, 16]\n",
      "Activation Function: ['relu', 'relu', 'relu', 'relu']\n",
      "Average Cross-Validation Accuracy: 96.36%\n"
     ]
    }
   ],
   "source": [
    "print(f'Best MLP Network Configuration:')\n",
    "print(f'Number of Layers: {best_params[0]}')\n",
    "print(f'Neurons per Layer: {best_params[1]}')\n",
    "print(f'Activation Function: {best_params[2]}')\n",
    "print(f'Average Cross-Validation Accuracy: {best_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicted values using MLP and PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "[0 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1\n",
      " 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 1\n",
      " 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1\n",
      " 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1\n",
      " 1 1 1 1 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(all_best_accuracies_MLP_PSO))\n",
    "print(len(all_predicted_MLP_PSO))\n",
    "max_acc = np.argmax(all_best_accuracies_MLP_PSO)\n",
    "predicted_MLP_PSO = all_predicted_MLP_PSO[max_acc]\n",
    "predicted_MLP_PSO = predicted_MLP_PSO.ravel()\n",
    "print(predicted_MLP_PSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_best_accuracies_RBF_PSO = []\n",
    "all_predicted_RBF_PSO = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 447)\n",
      "(550, 1)\n",
      "(159, 447)\n",
      "Accuracies for Different Parameter Combinations:\n",
      "Parameters: {'C': 0.1, 'gamma': 1} - Accuracy: 50.36\n",
      "Parameters: {'C': 0.1, 'gamma': 0.1} - Accuracy: 50.91\n",
      "Parameters: {'C': 0.1, 'gamma': 0.01} - Accuracy: 50.36\n",
      "Parameters: {'C': 0.1, 'gamma': 0.001} - Accuracy: 50.36\n",
      "Parameters: {'C': 1, 'gamma': 1} - Accuracy: 61.45\n",
      "Parameters: {'C': 1, 'gamma': 0.1} - Accuracy: 85.27\n",
      "Parameters: {'C': 1, 'gamma': 0.01} - Accuracy: 71.09\n",
      "Parameters: {'C': 1, 'gamma': 0.001} - Accuracy: 51.09\n",
      "Parameters: {'C': 10, 'gamma': 1} - Accuracy: 64.00\n",
      "Parameters: {'C': 10, 'gamma': 0.1} - Accuracy: 88.91\n",
      "Parameters: {'C': 10, 'gamma': 0.01} - Accuracy: 83.82\n",
      "Parameters: {'C': 10, 'gamma': 0.001} - Accuracy: 73.45\n",
      "Parameters: {'C': 15, 'gamma': 1} - Accuracy: 64.00\n",
      "Parameters: {'C': 15, 'gamma': 0.1} - Accuracy: 88.91\n",
      "Parameters: {'C': 15, 'gamma': 0.01} - Accuracy: 85.45\n",
      "Parameters: {'C': 15, 'gamma': 0.001} - Accuracy: 77.45\n",
      "Parameters: {'C': 18, 'gamma': 1} - Accuracy: 64.00\n",
      "Parameters: {'C': 18, 'gamma': 0.1} - Accuracy: 88.91\n",
      "Parameters: {'C': 18, 'gamma': 0.01} - Accuracy: 85.27\n",
      "Parameters: {'C': 18, 'gamma': 0.001} - Accuracy: 77.64\n",
      "Parameters: {'C': 100, 'gamma': 1} - Accuracy: 64.00\n",
      "Parameters: {'C': 100, 'gamma': 0.1} - Accuracy: 88.91\n",
      "Parameters: {'C': 100, 'gamma': 0.01} - Accuracy: 87.27\n",
      "Parameters: {'C': 100, 'gamma': 0.001} - Accuracy: 83.27\n",
      "------------------------------\n",
      "\n",
      "Best Parameters: {'C': 10, 'gamma': 0.1}\n",
      "Average Cross-Validation Accuracy: 88.91%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "train_data = X_train_PSO\n",
    "train_labels = training_data_labels.T\n",
    "testing_data = X_test\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(testing_data.shape)\n",
    "\n",
    "# Convert labels from -1 to 0 for compatibility with \"binary_crossentropy\" loss\n",
    "train_labels = (train_labels + 1) / 2\n",
    "\n",
    "train_labels = train_labels.flatten()\n",
    "\n",
    "svm_model = SVC(kernel='rbf')\n",
    "\n",
    "# Define the parameters\n",
    "Cs = [0.1, 1, 10, 15, 18, 100]\n",
    "gammas = [1, 0.1, 0.01, 0.001]\n",
    "\n",
    "best_params = {'C': None, 'gamma': None}\n",
    "best_accuracy = 0.0\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "print(\"Accuracies for Different Parameter Combinations:\")\n",
    "for C in Cs:\n",
    "    for gamma in gammas:\n",
    "\n",
    "        current_model = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "        cv_scores = cross_val_score(current_model, train_data, train_labels, cv=5, scoring='accuracy')\n",
    "        average_accuracy = np.mean(cv_scores)\n",
    "\n",
    "        current_model.fit(train_data, train_labels)\n",
    "        test_prediction = current_model.predict(testing_data)\n",
    "        #print(test_prediction.shape)\n",
    "\n",
    "        all_best_accuracies_RBF_PSO.append(average_accuracy)\n",
    "        all_predicted_RBF_PSO.append(test_prediction)\n",
    "\n",
    "        print(f\"Parameters: {{'C': {C}, 'gamma': {gamma}}} - Accuracy: {average_accuracy* 100:.2f}\")\n",
    "\n",
    "        if average_accuracy > best_accuracy:\n",
    "            best_accuracy = average_accuracy\n",
    "            best_params['C'] = C\n",
    "            best_params['gamma'] = gamma\n",
    "\n",
    "print('-' * 30)\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f'Average Cross-Validation Accuracy: {best_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicted values using RBF and PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(len(all_best_accuracies_RBF_PSO))\n",
    "print(len(all_predicted_RBF_PSO))\n",
    "max_acc = np.argmax(all_best_accuracies_RBF_PSO)\n",
    "predicted_RBF_PSO = all_predicted_RBF_PSO[max_acc]\n",
    "print(predicted_RBF_PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(159,)\n",
      "(159,)\n",
      "(159,)\n",
      "(159,)\n"
     ]
    }
   ],
   "source": [
    "print(type(predicted_MLP_Fisher))\n",
    "print(type(predicted_RBF_Fisher))\n",
    "print(type(predicted_MLP_PSO))\n",
    "print(type(predicted_RBF_PSO))\n",
    "\n",
    "print(predicted_MLP_Fisher.shape)\n",
    "print(predicted_RBF_Fisher.shape)\n",
    "print(predicted_MLP_PSO.shape)\n",
    "print(predicted_RBF_PSO.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_MLP_Fisher_final = np.where(predicted_MLP_Fisher == 0, -1 , predicted_MLP_Fisher)\n",
    "predicted_RBF_Fisher_final = np.where(predicted_RBF_Fisher == 0, -1 , predicted_RBF_Fisher)\n",
    "predicted_MLP_PSO_final = np.where(predicted_MLP_PSO == 0, -1 , predicted_MLP_PSO)\n",
    "predicted_RBF_PSO_final = np.where(predicted_RBF_PSO == 0, -1 , predicted_RBF_PSO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1  1  1 -1  1 -1  1  1 -1  1  1 -1  1 -1  1  1  1 -1 -1 -1  1 -1\n",
      "  1  1  1  1 -1  1 -1  1 -1 -1  1 -1 -1  1  1  1  1  1 -1  1  1 -1  1  1\n",
      "  1  1  1  1  1  1 -1 -1  1 -1  1  1 -1 -1  1  1  1 -1  1  1 -1 -1  1 -1\n",
      "  1  1  1  1  1 -1  1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1  1 -1 -1 -1  1\n",
      "  1  1  1 -1 -1  1 -1 -1  1  1  1 -1  1 -1  1  1 -1  1  1 -1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1 -1  1  1  1  1  1 -1  1\n",
      "  1 -1 -1  1  1  1  1 -1 -1 -1  1  1  1  1  1]\n",
      "[-1. -1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1.\n",
      " -1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1. -1.\n",
      " -1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1. -1.  1. -1. -1. -1. -1.\n",
      "  1.  1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
      "  1. -1.  1.  1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1.  1.  1.  1.  1.\n",
      " -1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1.\n",
      " -1. -1. -1.  1.  1. -1.  1. -1. -1. -1.  1.  1.  1. -1. -1.]\n",
      "[-1 -1  1  1  1 -1  1 -1  1  1 -1  1  1 -1 -1  1  1  1  1 -1 -1 -1  1 -1\n",
      " -1 -1  1  1  1  1 -1  1 -1 -1 -1 -1  1  1  1  1  1 -1  1  1  1 -1  1  1\n",
      "  1 -1  1  1  1  1 -1  1  1  1  1  1 -1  1  1  1  1  1 -1  1 -1 -1  1 -1\n",
      "  1  1 -1 -1  1  1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1\n",
      "  1  1  1  1 -1  1 -1 -1 -1  1  1 -1  1  1  1  1  1 -1  1 -1  1  1 -1 -1\n",
      "  1 -1  1  1  1 -1 -1  1 -1 -1  1  1  1  1  1  1 -1  1  1  1  1  1 -1  1\n",
      "  1 -1 -1  1  1  1  1  1 -1  1  1 -1  1 -1  1]\n",
      "[-1. -1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1. -1. -1.\n",
      " -1.  1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1.\n",
      " -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1. -1.  1. -1.\n",
      "  1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1.\n",
      "  1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1.\n",
      " -1.  1. -1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.\n",
      "  1. -1. -1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_MLP_Fisher_final)\n",
    "print(predicted_RBF_Fisher_final)\n",
    "print(predicted_MLP_PSO_final)\n",
    "print(predicted_RBF_PSO_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0\n",
      " 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 1 1 0 0 1 0 1 1\n",
      " 1 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1\n",
      " 1 1 1 0 0 0 1 1 1 1 1]\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      "[0 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1\n",
      " 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 1 1\n",
      " 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1\n",
      " 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1\n",
      " 1 1 1 1 0 1 1 0 1 0 1]\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_MLP_Fisher)\n",
    "print(predicted_RBF_Fisher)\n",
    "print(predicted_MLP_PSO)\n",
    "print(predicted_RBF_PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "scipy.io.savemat('Test_MLP1.mat', {'Test_MLP1': predicted_MLP_Fisher_final})\n",
    "scipy.io.savemat('Test_RBF1.mat', {'Test_RBF1': predicted_RBF_Fisher_final})\n",
    "scipy.io.savemat('Test_MLP2.mat', {'Test_MLP2': predicted_MLP_PSO_final})\n",
    "scipy.io.savemat('Test_RBF2.mat', {'Test_RBF2': predicted_RBF_PSO_final})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
